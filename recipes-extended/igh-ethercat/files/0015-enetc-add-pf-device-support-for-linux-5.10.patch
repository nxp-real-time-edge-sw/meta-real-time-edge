From 0373002623b91c878bd24ad5d778863f32060e2f Mon Sep 17 00:00:00 2001
From: Wenbin Song <wenbin.song@nxp.com>
Date: Wed, 30 Jun 2021 16:58:01 +0800
Subject: [PATCH 15/18] enetc: add pf device support for linux 5.10

Signed-off-by: Wenbin Song <wenbin.song@nxp.com>
Upstream-Status: Pending
---
 configure.ac              |    4 +-
 devices/enetc/Kbuild.in   |   13 +-
 devices/enetc/Makefile.am |    5 +-
 devices/enetc/enetc.c     |   21 +-
 devices/enetc/enetc_pf.c  |  666 ++++++++++++
 devices/enetc/enetc_pf.h  |   60 ++
 devices/enetc/enetc_ptp.c |  163 ---
 devices/enetc/enetc_qos.c | 1576 +++++++++++++++++++++++++++++
 devices/enetc/enetc_tsn.c | 2010 -------------------------------------
 9 files changed, 2333 insertions(+), 2185 deletions(-)
 create mode 100644 devices/enetc/enetc_pf.c
 create mode 100644 devices/enetc/enetc_pf.h
 delete mode 100644 devices/enetc/enetc_ptp.c
 create mode 100644 devices/enetc/enetc_qos.c
 delete mode 100644 devices/enetc/enetc_tsn.c

diff --git a/configure.ac b/configure.ac
index 58257b0..f2c7cf5 100644
--- a/configure.ac
+++ b/configure.ac
@@ -212,12 +212,12 @@ fi
 AC_SUBST(KERNEL_8139TOO,[$kernel8139too])
 
 #------------------------------------------------------------------------------
-# enetc vf driver
+# enetc driver
 #------------------------------------------------------------------------------
 
 AC_ARG_ENABLE([enetc],
     AS_HELP_STRING([--enable-enetc],
-                   [Enable enetc vf driver]),
+                   [Enable enetc driver]),
     [
         case "${enableval}" in
             yes) enable_enetc=1
diff --git a/devices/enetc/Kbuild.in b/devices/enetc/Kbuild.in
index e938df2..2e3f103 100644
--- a/devices/enetc/Kbuild.in
+++ b/devices/enetc/Kbuild.in
@@ -39,14 +39,25 @@ REV := $(shell if test -s $(TOPDIR)/revision; then \
 	fi)
 
 ifeq (@ENABLE_ENETC@,1)
-	EC_ENETC_OBJ := \
+	EC_ENETC_VF_OBJ := \
 		enetc.o \
 		enetc_vf.o \
 		enetc_cbdr.o \
 		enetc_qos.o \
 		enetc_ethtool.o
+
+	obj-m += ec_enetc_vf.o
+	EC_ENETC_OBJ := \
+		enetc.o \
+		enetc_pf.o \
+		enetc_cbdr.o \
+		enetc_qos.o \
+		enetc_ethtool.o
+
 	obj-m += ec_enetc.o
 	ec_enetc-objs := $(EC_ENETC_OBJ)
+	ec_enetc_vf-objs := $(EC_ENETC_VF_OBJ)
+	CFLAGS_$(EC_ENETC_VF_OBJ) = -DREV=$(REV)
 	CFLAGS_$(EC_ENETC_OBJ) = -DREV=$(REV)
 endif
 
diff --git a/devices/enetc/Makefile.am b/devices/enetc/Makefile.am
index b8fec1c..96cf5b4 100644
--- a/devices/enetc/Makefile.am
+++ b/devices/enetc/Makefile.am
@@ -30,11 +30,10 @@
 EXTRA_DIST = \
 	enetc.c \
 	enetc_ethtool.c \
-	enetc_tsn.c \
 	enetc_cbdr.c \
 	enetc_qos.c \
-	enetc_ptp.c \
-	enetc_vf.c 
+	enetc_vf.c \
+	enetc_pf.c
 
 BUILT_SOURCES = \
 	Kbuild
diff --git a/devices/enetc/enetc.c b/devices/enetc/enetc.c
index 7839b06..8eb19b3 100644
--- a/devices/enetc/enetc.c
+++ b/devices/enetc/enetc.c
@@ -1046,20 +1046,21 @@ static int enetc_phylink_connect(struct net_device *ndev)
 	struct enetc_ndev_priv *priv = netdev_priv(ndev);
 	struct ethtool_eee edata;
 	int err;
-
 	if (!priv->phylink)
 		return 0; /* phy-less mode */
 
+	rtnl_lock();
 	err = phylink_of_phy_connect(priv->phylink, priv->dev->of_node, 0);
 	if (err) {
 		dev_err(&ndev->dev, "could not attach to PHY\n");
+		rtnl_unlock();
 		return err;
 	}
 
 	/* disable EEE autoneg, until ENETC driver supports it */
 	memset(&edata, 0, sizeof(struct ethtool_eee));
 	phylink_ethtool_set_eee(priv->phylink, &edata);
-
+	rtnl_unlock();
 	return 0;
 }
 
@@ -1067,8 +1068,11 @@ void enetc_start(struct net_device *ndev)
 {
 	struct enetc_ndev_priv *priv = netdev_priv(ndev);
 
-	if (priv->phylink)
+	if (priv->phylink) {
+		rtnl_lock();
 		phylink_start(priv->phylink);
+		rtnl_unlock();
+	}
 }
 
 int enetc_open(struct net_device *ndev)
@@ -1108,9 +1112,11 @@ err_phy_connect:
 void enetc_stop(struct net_device *ndev)
 {
 	struct enetc_ndev_priv *priv = netdev_priv(ndev);
-	if (priv->phylink)
+	if (priv->phylink) {
+		rtnl_lock();
 		phylink_stop(priv->phylink);
-
+		rtnl_unlock();
+	}
 }
 
 int enetc_close(struct net_device *ndev)
@@ -1120,8 +1126,11 @@ int enetc_close(struct net_device *ndev)
 	enetc_stop(ndev);
 	enetc_clear_bdrs(priv);
 
-	if (priv->phylink)
+	if (priv->phylink) {
+		rtnl_lock();
 		phylink_disconnect_phy(priv->phylink);
+		rtnl_unlock();
+	}
 	enetc_free_rxtx_rings(priv);
 	enetc_free_rx_resources(priv);
 	enetc_free_tx_resources(priv);
diff --git a/devices/enetc/enetc_pf.c b/devices/enetc/enetc_pf.c
new file mode 100644
index 0000000..778db4b
--- /dev/null
+++ b/devices/enetc/enetc_pf.c
@@ -0,0 +1,666 @@
+// SPDX-License-Identifier: (GPL-2.0+ OR BSD-3-Clause)
+/* Copyright 2017-2021 NXP */
+
+#include <linux/mdio.h>
+#include <linux/module.h>
+#include <linux/fsl/enetc_mdio.h>
+#include <linux/of_mdio.h>
+#include <linux/of_net.h>
+#include "enetc_pf.h"
+#include "../ecdev.h"
+
+#define ENETC_DRV_NAME_STR "ENETC PF driver"
+
+static void enetc_pf_get_primary_mac_addr(struct enetc_hw *hw, int si, u8 *addr)
+{
+	u32 upper = __raw_readl(hw->port + ENETC_PSIPMAR0(si));
+	u16 lower = __raw_readw(hw->port + ENETC_PSIPMAR1(si));
+
+	*(u32 *)addr = upper;
+	*(u16 *)(addr + 4) = lower;
+}
+
+static void enetc_pf_set_primary_mac_addr(struct enetc_hw *hw, int si,
+					  const u8 *addr)
+{
+	u32 upper = *(const u32 *)addr;
+	u16 lower = *(const u16 *)(addr + 4);
+
+	__raw_writel(upper, hw->port + ENETC_PSIPMAR0(si));
+	__raw_writew(lower, hw->port + ENETC_PSIPMAR1(si));
+}
+
+static void enetc_port_setup_primary_mac_address(struct enetc_si *si)
+{
+	unsigned char mac_addr[MAX_ADDR_LEN];
+	struct enetc_pf *pf = enetc_si_priv(si);
+	struct enetc_hw *hw = &si->hw;
+	int i;
+
+	/* check MAC addresses for PF and all VFs, if any is 0 set it ro rand */
+	for (i = 0; i < pf->total_vfs + 1; i++) {
+		enetc_pf_get_primary_mac_addr(hw, i, mac_addr);
+		if (!is_zero_ether_addr(mac_addr))
+			continue;
+		eth_random_addr(mac_addr);
+		dev_info(&si->pdev->dev, "no MAC address specified for SI%d, using %pM\n",
+			 i, mac_addr);
+		enetc_pf_set_primary_mac_addr(hw, i, mac_addr);
+	}
+}
+
+static void enetc_port_assign_rfs_entries(struct enetc_si *si)
+{
+	struct enetc_pf *pf = enetc_si_priv(si);
+	struct enetc_hw *hw = &si->hw;
+	int num_entries, vf_entries, i;
+	u32 val;
+
+	/* split RFS entries between functions */
+	val = enetc_port_rd(hw, ENETC_PRFSCAPR);
+	num_entries = ENETC_PRFSCAPR_GET_NUM_RFS(val);
+	vf_entries = num_entries / (pf->total_vfs + 1);
+
+	for (i = 0; i < pf->total_vfs; i++)
+		enetc_port_wr(hw, ENETC_PSIRFSCFGR(i + 1), vf_entries);
+	enetc_port_wr(hw, ENETC_PSIRFSCFGR(0),
+		      num_entries - vf_entries * pf->total_vfs);
+
+	/* enable RFS on port */
+	enetc_port_wr(hw, ENETC_PRFSMR, ENETC_PRFSMR_RFSE);
+}
+
+static void enetc_port_si_configure(struct enetc_si *si)
+{
+	struct enetc_pf *pf = enetc_si_priv(si);
+	struct enetc_hw *hw = &si->hw;
+	int num_rings, i;
+	u32 val;
+
+	val = enetc_port_rd(hw, ENETC_PCAPR0);
+	num_rings = min(ENETC_PCAPR0_RXBDR(val), ENETC_PCAPR0_TXBDR(val));
+
+	val = ENETC_PSICFGR0_SET_TXBDR(ENETC_PF_NUM_RINGS);
+	val |= ENETC_PSICFGR0_SET_RXBDR(ENETC_PF_NUM_RINGS);
+
+	if (unlikely(num_rings < ENETC_PF_NUM_RINGS)) {
+		val = ENETC_PSICFGR0_SET_TXBDR(num_rings);
+		val |= ENETC_PSICFGR0_SET_RXBDR(num_rings);
+
+		dev_warn(&si->pdev->dev, "Found %d rings, expected %d!\n",
+			 num_rings, ENETC_PF_NUM_RINGS);
+
+		num_rings = 0;
+	}
+
+	/* Add default one-time settings for SI0 (PF) */
+	val |= ENETC_PSICFGR0_SIVC(ENETC_VLAN_TYPE_C | ENETC_VLAN_TYPE_S);
+
+	enetc_port_wr(hw, ENETC_PSICFGR0(0), val);
+
+	if (num_rings)
+		num_rings -= ENETC_PF_NUM_RINGS;
+
+	/* Configure the SIs for each available VF */
+	val = ENETC_PSICFGR0_SIVC(ENETC_VLAN_TYPE_C | ENETC_VLAN_TYPE_S);
+	val |= ENETC_PSICFGR0_VTE | ENETC_PSICFGR0_SIVIE;
+
+	if (num_rings) {
+		num_rings /= pf->total_vfs;
+		val |= ENETC_PSICFGR0_SET_TXBDR(num_rings);
+		val |= ENETC_PSICFGR0_SET_RXBDR(num_rings);
+	}
+
+	for (i = 0; i < pf->total_vfs; i++)
+		enetc_port_wr(hw, ENETC_PSICFGR0(i + 1), val);
+
+	/* Port level VLAN settings */
+	val = ENETC_PVCLCTR_OVTPIDL(ENETC_VLAN_TYPE_C | ENETC_VLAN_TYPE_S);
+	enetc_port_wr(hw, ENETC_PVCLCTR, val);
+	/* use outer tag for VLAN filtering */
+	enetc_port_wr(hw, ENETC_PSIVLANFMR, ENETC_PSIVLANFMR_VS);
+}
+
+static void enetc_configure_port_mac(struct enetc_hw *hw)
+{
+	enetc_port_wr(hw, ENETC_PM0_MAXFRM,
+		      ENETC_SET_MAXFRM(ENETC_RX_MAXFRM_SIZE));
+
+	enetc_port_wr(hw, ENETC_PTCMSDUR(0), ENETC_MAC_MAXFRM_SIZE);
+	enetc_port_wr(hw, ENETC_PTXMBAR, 2 * ENETC_MAC_MAXFRM_SIZE);
+
+	enetc_port_wr(hw, ENETC_PM0_CMD_CFG, ENETC_PM0_CMD_PHY_TX_EN |
+		      ENETC_PM0_CMD_TXP	| ENETC_PM0_PROMISC);
+
+	enetc_port_wr(hw, ENETC_PM1_CMD_CFG, ENETC_PM0_CMD_PHY_TX_EN |
+		      ENETC_PM0_CMD_TXP	| ENETC_PM0_PROMISC);
+}
+
+static void enetc_mac_config(struct enetc_hw *hw, phy_interface_t phy_mode)
+{
+	/* set auto-speed for RGMII */
+	if (enetc_port_rd(hw, ENETC_PM0_IF_MODE) & ENETC_PMO_IFM_RG ||
+	    phy_interface_mode_is_rgmii(phy_mode)) {
+		enetc_port_wr(hw, ENETC_PM0_IF_MODE, ENETC_PM0_IFM_RGAUTO);
+		enetc_port_wr(hw, ENETC_PM1_IF_MODE, ENETC_PM0_IFM_RGAUTO);
+	}
+
+	if (phy_mode == PHY_INTERFACE_MODE_USXGMII) {
+		enetc_port_wr(hw, ENETC_PM0_IF_MODE, ENETC_PM0_IFM_XGMII);
+		enetc_port_wr(hw, ENETC_PM1_IF_MODE, ENETC_PM0_IFM_XGMII);
+	}
+
+	/* on LS1028A the MAC Rx FIFO defaults to value 2, which is too high and
+	 * may lead to Rx lock-up under traffic.  Set it to 1 instead, as
+	 * recommended by the hardware team.
+	 */
+	enetc_port_wr(hw, ENETC_PM0_RX_FIFO, ENETC_PM0_RX_FIFO_VAL);
+}
+
+static void enetc_mac_enable(struct enetc_hw *hw, bool en)
+{
+	u32 val = enetc_port_rd(hw, ENETC_PM0_CMD_CFG);
+
+	val &= ~(ENETC_PM0_TX_EN | ENETC_PM0_RX_EN);
+	val |= en ? (ENETC_PM0_TX_EN | ENETC_PM0_RX_EN) : 0;
+
+	enetc_port_wr(hw, ENETC_PM0_CMD_CFG, val);
+	enetc_port_wr(hw, ENETC_PM1_CMD_CFG, val);
+}
+
+static void enetc_configure_port_pmac(struct enetc_hw *hw)
+{
+	u32 temp;
+
+	/* Set pMAC step lock */
+	temp = enetc_port_rd(hw, ENETC_PFPMR);
+	enetc_port_wr(hw, ENETC_PFPMR,
+		      temp | ENETC_PFPMR_PMACE | ENETC_PFPMR_MWLM);
+
+	temp = enetc_port_rd(hw, ENETC_MMCSR);
+	enetc_port_wr(hw, ENETC_MMCSR, temp | ENETC_MMCSR_ME);
+}
+
+static void enetc_configure_port(struct enetc_pf *pf)
+{
+	u8 hash_key[ENETC_RSSHASH_KEY_SIZE];
+	struct enetc_hw *hw = &pf->si->hw;
+
+	enetc_configure_port_pmac(hw);
+
+	enetc_configure_port_mac(hw);
+
+	enetc_port_si_configure(pf->si);
+
+	/* set up hash key */
+	get_random_bytes(hash_key, ENETC_RSSHASH_KEY_SIZE);
+	enetc_set_rss_key(hw, hash_key);
+
+	/* split up RFS entries */
+	enetc_port_assign_rfs_entries(pf->si);
+
+	/* fix-up primary MAC addresses, if not set already */
+	enetc_port_setup_primary_mac_address(pf->si);
+
+	/* enforce VLAN promisc mode for all SIs */
+	pf->vlan_promisc_simap = ENETC_VLAN_PROMISC_MAP_ALL;
+
+	enetc_port_wr(hw, ENETC_PSIPMR, 0);
+
+	/* enable port */
+	enetc_port_wr(hw, ENETC_PMR, ENETC_PMR_EN);
+}
+
+static const struct net_device_ops enetc_ndev_ops = {
+	.ndo_open		= enetc_open,
+	.ndo_stop		= enetc_close,
+	.ndo_start_xmit		= enetc_xmit,
+};
+
+static void enetc_pf_netdev_setup(struct enetc_si *si, struct net_device *ndev,
+				  const struct net_device_ops *ndev_ops)
+{
+	struct enetc_ndev_priv *priv = netdev_priv(ndev);
+
+	SET_NETDEV_DEV(ndev, &si->pdev->dev);
+	priv->ndev = ndev;
+	priv->si = si;
+	priv->dev = &si->pdev->dev;
+	si->ndev = ndev;
+
+	priv->msg_enable = (NETIF_MSG_WOL << 1) - 1;
+	ndev->netdev_ops = ndev_ops;
+	enetc_set_ethtool_ops(ndev);
+	ndev->watchdog_timeo = 5 * HZ;
+	ndev->max_mtu = ENETC_MAX_MTU;
+
+	ndev->hw_features = NETIF_F_SG | NETIF_F_RXCSUM | NETIF_F_HW_CSUM |
+			    NETIF_F_HW_VLAN_CTAG_TX | NETIF_F_HW_VLAN_CTAG_RX |
+			    NETIF_F_HW_VLAN_CTAG_FILTER | NETIF_F_LOOPBACK;
+	ndev->features = NETIF_F_HIGHDMA | NETIF_F_SG |
+			 NETIF_F_RXCSUM | NETIF_F_HW_CSUM |
+			 NETIF_F_HW_VLAN_CTAG_TX |
+			 NETIF_F_HW_VLAN_CTAG_RX;
+
+	if (si->num_rss)
+		ndev->hw_features |= NETIF_F_RXHASH;
+
+	if (si->errata & ENETC_ERR_TXCSUM) {
+		ndev->hw_features &= ~NETIF_F_HW_CSUM;
+		ndev->features &= ~NETIF_F_HW_CSUM;
+	}
+
+	ndev->priv_flags |= IFF_UNICAST_FLT;
+
+	if (si->hw_features & ENETC_SI_F_QBV)
+		priv->active_offloads |= ENETC_F_QBV;
+
+	if (si->hw_features & ENETC_SI_F_PSFP && !enetc_psfp_enable(priv)) {
+		priv->active_offloads |= ENETC_F_QCI;
+		ndev->features |= NETIF_F_HW_TC;
+		ndev->hw_features |= NETIF_F_HW_TC;
+	}
+
+	/* pick up primary MAC address from SI */
+	enetc_get_primary_mac_addr(&si->hw, ndev->dev_addr);
+}
+
+static int enetc_mdio_probe(struct enetc_pf *pf, struct device_node *np)
+{
+	struct device *dev = &pf->si->pdev->dev;
+	struct enetc_mdio_priv *mdio_priv;
+	struct mii_bus *bus;
+	int err;
+
+	bus = devm_mdiobus_alloc_size(dev, sizeof(*mdio_priv));
+	if (!bus)
+		return -ENOMEM;
+
+	bus->name = "Freescale ENETC MDIO Bus";
+	bus->read = enetc_mdio_read;
+	bus->write = enetc_mdio_write;
+	bus->parent = dev;
+	mdio_priv = bus->priv;
+	mdio_priv->hw = &pf->si->hw;
+	mdio_priv->mdio_base = ENETC_EMDIO_BASE;
+	snprintf(bus->id, MII_BUS_ID_SIZE, "%s", dev_name(dev));
+
+	err = of_mdiobus_register(bus, np);
+	if (err) {
+		dev_err(dev, "cannot register MDIO bus\n");
+		return err;
+	}
+
+	pf->mdio = bus;
+
+	return 0;
+}
+
+static void enetc_mdio_remove(struct enetc_pf *pf)
+{
+	if (pf->mdio)
+		mdiobus_unregister(pf->mdio);
+}
+
+static int enetc_imdio_create(struct enetc_pf *pf)
+{
+	struct device *dev = &pf->si->pdev->dev;
+	struct enetc_mdio_priv *mdio_priv;
+	struct lynx_pcs *pcs_lynx;
+	struct mdio_device *pcs;
+	struct mii_bus *bus;
+	int err;
+
+	bus = mdiobus_alloc_size(sizeof(*mdio_priv));
+	if (!bus)
+		return -ENOMEM;
+
+	bus->name = "Freescale ENETC internal MDIO Bus";
+	bus->read = enetc_mdio_read;
+	bus->write = enetc_mdio_write;
+	bus->parent = dev;
+	bus->phy_mask = ~0;
+	mdio_priv = bus->priv;
+	mdio_priv->hw = &pf->si->hw;
+	mdio_priv->mdio_base = ENETC_PM_IMDIO_BASE;
+	snprintf(bus->id, MII_BUS_ID_SIZE, "%s-imdio", dev_name(dev));
+
+	err = mdiobus_register(bus);
+	if (err) {
+		dev_err(dev, "cannot register internal MDIO bus (%d)\n", err);
+		goto free_mdio_bus;
+	}
+
+	pcs = mdio_device_create(bus, 0);
+	if (IS_ERR(pcs)) {
+		err = PTR_ERR(pcs);
+		dev_err(dev, "cannot create pcs (%d)\n", err);
+		goto unregister_mdiobus;
+	}
+
+	pcs_lynx = lynx_pcs_create(pcs);
+	if (!pcs_lynx) {
+		mdio_device_free(pcs);
+		err = -ENOMEM;
+		dev_err(dev, "cannot create lynx pcs (%d)\n", err);
+		goto unregister_mdiobus;
+	}
+
+	pf->imdio = bus;
+	pf->pcs = pcs_lynx;
+
+	return 0;
+
+unregister_mdiobus:
+	mdiobus_unregister(bus);
+free_mdio_bus:
+	mdiobus_free(bus);
+	return err;
+}
+
+static void enetc_imdio_remove(struct enetc_pf *pf)
+{
+	if (pf->pcs) {
+		mdio_device_free(pf->pcs->mdio);
+		lynx_pcs_destroy(pf->pcs);
+	}
+	if (pf->imdio) {
+		mdiobus_unregister(pf->imdio);
+		mdiobus_free(pf->imdio);
+	}
+}
+
+static bool enetc_port_has_pcs(struct enetc_pf *pf)
+{
+	return (pf->if_mode == PHY_INTERFACE_MODE_SGMII ||
+		pf->if_mode == PHY_INTERFACE_MODE_2500BASEX ||
+		pf->if_mode == PHY_INTERFACE_MODE_USXGMII);
+}
+
+static int enetc_mdiobus_create(struct enetc_pf *pf)
+{
+	struct device *dev = &pf->si->pdev->dev;
+	struct device_node *mdio_np;
+	int err;
+
+	mdio_np = of_get_child_by_name(dev->of_node, "mdio");
+	if (mdio_np) {
+		err = enetc_mdio_probe(pf, mdio_np);
+
+		of_node_put(mdio_np);
+		if (err)
+			return err;
+	}
+
+	if (enetc_port_has_pcs(pf)) {
+		err = enetc_imdio_create(pf);
+		if (err) {
+			enetc_mdio_remove(pf);
+			return err;
+		}
+	}
+
+	return 0;
+}
+
+static void enetc_mdiobus_destroy(struct enetc_pf *pf)
+{
+	enetc_mdio_remove(pf);
+	enetc_imdio_remove(pf);
+}
+
+static void enetc_pl_mac_validate(struct phylink_config *config,
+				  unsigned long *supported,
+				  struct phylink_link_state *state)
+{
+	__ETHTOOL_DECLARE_LINK_MODE_MASK(mask) = { 0, };
+
+	if (state->interface != PHY_INTERFACE_MODE_NA &&
+	    state->interface != PHY_INTERFACE_MODE_INTERNAL &&
+	    state->interface != PHY_INTERFACE_MODE_SGMII &&
+	    state->interface != PHY_INTERFACE_MODE_2500BASEX &&
+	    state->interface != PHY_INTERFACE_MODE_USXGMII &&
+	    !phy_interface_mode_is_rgmii(state->interface)) {
+		bitmap_zero(supported, __ETHTOOL_LINK_MODE_MASK_NBITS);
+		return;
+	}
+
+	phylink_set_port_modes(mask);
+	phylink_set(mask, Autoneg);
+	phylink_set(mask, Pause);
+	phylink_set(mask, Asym_Pause);
+	phylink_set(mask, 10baseT_Half);
+	phylink_set(mask, 10baseT_Full);
+	phylink_set(mask, 100baseT_Half);
+	phylink_set(mask, 100baseT_Full);
+	phylink_set(mask, 100baseT_Half);
+	phylink_set(mask, 1000baseT_Half);
+	phylink_set(mask, 1000baseT_Full);
+
+	if (state->interface == PHY_INTERFACE_MODE_INTERNAL ||
+	    state->interface == PHY_INTERFACE_MODE_2500BASEX ||
+	    state->interface == PHY_INTERFACE_MODE_USXGMII) {
+		phylink_set(mask, 2500baseT_Full);
+		phylink_set(mask, 2500baseX_Full);
+	}
+
+	bitmap_and(supported, supported, mask,
+		   __ETHTOOL_LINK_MODE_MASK_NBITS);
+	bitmap_and(state->advertising, state->advertising, mask,
+		   __ETHTOOL_LINK_MODE_MASK_NBITS);
+}
+
+static void enetc_pl_mac_config(struct phylink_config *config,
+				unsigned int mode,
+				const struct phylink_link_state *state)
+{
+	struct enetc_pf *pf = phylink_to_enetc_pf(config);
+	struct enetc_ndev_priv *priv;
+
+	enetc_mac_config(&pf->si->hw, state->interface);
+
+	priv = netdev_priv(pf->si->ndev);
+	if (pf->pcs)
+		phylink_set_pcs(priv->phylink, &pf->pcs->pcs);
+}
+
+static void enetc_pl_mac_link_up(struct phylink_config *config,
+				 struct phy_device *phy, unsigned int mode,
+				 phy_interface_t interface, int speed,
+				 int duplex, bool tx_pause, bool rx_pause)
+{
+	struct enetc_pf *pf = phylink_to_enetc_pf(config);
+	struct enetc_ndev_priv *priv;
+
+	priv = netdev_priv(pf->si->ndev);
+	if (priv->active_offloads & ENETC_F_QBV)
+		enetc_sched_speed_set(priv, speed);
+
+	enetc_mac_enable(&pf->si->hw, true);
+}
+
+static void enetc_pl_mac_link_down(struct phylink_config *config,
+				   unsigned int mode,
+				   phy_interface_t interface)
+{
+	struct enetc_pf *pf = phylink_to_enetc_pf(config);
+
+	enetc_mac_enable(&pf->si->hw, false);
+}
+
+static const struct phylink_mac_ops enetc_mac_phylink_ops = {
+	.validate = enetc_pl_mac_validate,
+	.mac_config = enetc_pl_mac_config,
+	.mac_link_up = enetc_pl_mac_link_up,
+	.mac_link_down = enetc_pl_mac_link_down,
+};
+
+static int enetc_phylink_create(struct enetc_ndev_priv *priv)
+{
+	struct enetc_pf *pf = enetc_si_priv(priv->si);
+	struct device *dev = &pf->si->pdev->dev;
+	struct phylink *phylink;
+	int err;
+
+	pf->phylink_config.dev = &priv->ndev->dev;
+	pf->phylink_config.type = PHYLINK_NETDEV;
+
+	phylink = phylink_create(&pf->phylink_config,
+				 of_fwnode_handle(dev->of_node),
+				 pf->if_mode, &enetc_mac_phylink_ops);
+	if (IS_ERR(phylink)) {
+		err = PTR_ERR(phylink);
+		return err;
+	}
+
+	priv->phylink = phylink;
+
+	return 0;
+}
+
+static void enetc_phylink_destroy(struct enetc_ndev_priv *priv)
+{
+	if (priv->phylink)
+		phylink_destroy(priv->phylink);
+}
+
+static int enetc_pf_probe(struct pci_dev *pdev,
+			  const struct pci_device_id *ent)
+{
+	struct enetc_ndev_priv *priv;
+	struct pci_dev *ptp_pdev;
+	struct net_device *ndev;
+	struct enetc_si *si;
+	struct enetc_pf *pf;
+	int err;
+
+	if (pdev->dev.of_node && !of_device_is_available(pdev->dev.of_node)) {
+		dev_info(&pdev->dev, "device is disabled, skipping\n");
+		return -ENODEV;
+	}
+
+	err = enetc_pci_probe(pdev, KBUILD_MODNAME, sizeof(*pf));
+	if (err) {
+		dev_err(&pdev->dev, "PCI probing failed\n");
+		return err;
+	}
+
+	si = pci_get_drvdata(pdev);
+	if (!si->hw.port || !si->hw.global) {
+		err = -ENODEV;
+		dev_err(&pdev->dev, "could not map PF space, probing a VF?\n");
+		goto err_map_pf_space;
+	}
+
+	pf = enetc_si_priv(si);
+	pf->si = si;
+	pf->total_vfs = pci_sriov_get_totalvfs(pdev);
+
+	enetc_configure_port(pf);
+
+	enetc_get_si_caps(si);
+
+	ndev = alloc_etherdev_mq(sizeof(*priv), ENETC_MAX_NUM_TXQS);
+	if (!ndev) {
+		err = -ENOMEM;
+		dev_err(&pdev->dev, "netdev creation failed\n");
+		goto err_alloc_netdev;
+	}
+
+	enetc_pf_netdev_setup(si, ndev, &enetc_ndev_ops);
+
+	priv = netdev_priv(ndev);
+
+	enetc_init_si_rings_params(priv);
+
+	err = enetc_alloc_si_resources(priv);
+	if (err) {
+		dev_err(&pdev->dev, "SI resource alloc failed\n");
+		goto err_alloc_si_res;
+	}
+
+	ptp_pdev = pci_get_device(PCI_VENDOR_ID_FREESCALE, ENETC_DEV_ID_PTP,
+				  NULL);
+	if (!ptp_pdev) {
+		dev_err(&pdev->dev, "no PTP device found\n");
+		err = -ENODEV;
+		goto err_get_ptp;
+	}
+
+	priv->ptp_dev = &ptp_pdev->dev;
+	if (enetc_alloc_rings(priv) < 0)
+		goto err_get_ptp;
+
+	if (!of_get_phy_mode(pdev->dev.of_node, &pf->if_mode)) {
+		err = enetc_mdiobus_create(pf);
+		if (err)
+			goto err_mdiobus_create;
+
+		err = enetc_phylink_create(priv);
+		if (err)
+			goto err_phylink_create;
+	}
+
+        priv->ecdev = ecdev_offer(ndev, ec_poll, THIS_MODULE);
+        if (ecdev_open(priv->ecdev)) {
+                ecdev_withdraw(priv->ecdev);
+                goto err_reg_ec_net;
+        }
+
+	return 0;
+
+err_reg_ec_net:
+	enetc_phylink_destroy(priv);
+err_phylink_create:
+	enetc_mdiobus_destroy(pf);
+err_mdiobus_create:
+err_get_ptp:
+	enetc_free_si_resources(priv);
+	enetc_free_rings(priv);
+err_alloc_si_res:
+	si->ndev = NULL;
+	free_netdev(ndev);
+err_alloc_netdev:
+err_map_pf_space:
+	enetc_pci_remove(pdev);
+
+	return err;
+}
+
+static void enetc_pf_remove(struct pci_dev *pdev)
+{
+	struct enetc_si *si = pci_get_drvdata(pdev);
+	struct enetc_pf *pf = enetc_si_priv(si);
+	struct enetc_ndev_priv *priv;
+
+	priv = netdev_priv(si->ndev);
+
+	ecdev_close(priv->ecdev);
+	ecdev_withdraw(priv->ecdev);
+
+	enetc_phylink_destroy(priv);
+	enetc_mdiobus_destroy(pf);
+
+	enetc_free_si_resources(priv);
+
+	free_netdev(si->ndev);
+
+	enetc_pci_remove(pdev);
+}
+
+static const struct pci_device_id enetc_pf_id_table[] = {
+	{ PCI_DEVICE(PCI_VENDOR_ID_FREESCALE, ENETC_DEV_ID_PF) },
+	{ 0, } /* End of table. */
+};
+MODULE_DEVICE_TABLE(pci, enetc_pf_id_table);
+
+static struct pci_driver enetc_pf_driver = {
+	.name = KBUILD_MODNAME,
+	.id_table = enetc_pf_id_table,
+	.probe = enetc_pf_probe,
+	.remove = enetc_pf_remove,
+};
+module_pci_driver(enetc_pf_driver);
+
+MODULE_DESCRIPTION(ENETC_DRV_NAME_STR);
+MODULE_LICENSE("Dual BSD/GPL");
diff --git a/devices/enetc/enetc_pf.h b/devices/enetc/enetc_pf.h
new file mode 100644
index 0000000..263946c
--- /dev/null
+++ b/devices/enetc/enetc_pf.h
@@ -0,0 +1,60 @@
+/* SPDX-License-Identifier: (GPL-2.0+ OR BSD-3-Clause) */
+/* Copyright 2017-2019 NXP */
+
+#include "enetc.h"
+#include <linux/pcs-lynx.h>
+
+#define ENETC_PF_NUM_RINGS	8
+
+enum enetc_mac_addr_type {UC, MC, MADDR_TYPE};
+#define ENETC_MAX_NUM_MAC_FLT	((ENETC_MAX_NUM_VFS + 1) * MADDR_TYPE)
+
+#define ENETC_MADDR_HASH_TBL_SZ	64
+struct enetc_mac_filter {
+	union {
+		char mac_addr[ETH_ALEN];
+		DECLARE_BITMAP(mac_hash_table, ENETC_MADDR_HASH_TBL_SZ);
+	};
+	int mac_addr_cnt;
+};
+
+#define ENETC_VLAN_HT_SIZE	64
+
+enum enetc_vf_flags {
+	ENETC_VF_FLAG_PF_SET_MAC	= BIT(0),
+};
+
+struct enetc_vf_state {
+	enum enetc_vf_flags flags;
+};
+
+struct enetc_pf {
+	struct enetc_si *si;
+	int num_vfs; /* number of active VFs, after sriov_init */
+	int total_vfs; /* max number of VFs, set for PF at probe */
+	struct enetc_vf_state *vf_state;
+
+	struct enetc_mac_filter mac_filter[ENETC_MAX_NUM_MAC_FLT];
+
+	struct enetc_msg_swbd rxmsg[ENETC_MAX_NUM_VFS];
+	struct work_struct msg_task;
+	char msg_int_name[ENETC_INT_NAME_MAX];
+
+	char vlan_promisc_simap; /* bitmap of SIs in VLAN promisc mode */
+	DECLARE_BITMAP(vlan_ht_filter, ENETC_VLAN_HT_SIZE);
+	DECLARE_BITMAP(active_vlans, VLAN_N_VID);
+
+	struct mii_bus *mdio; /* saved for cleanup */
+	struct mii_bus *imdio;
+	struct lynx_pcs *pcs;
+
+	phy_interface_t if_mode;
+	struct phylink_config phylink_config;
+};
+
+#define phylink_to_enetc_pf(config) \
+	container_of((config), struct enetc_pf, phylink_config)
+
+int enetc_msg_psi_init(struct enetc_pf *pf);
+void enetc_msg_psi_free(struct enetc_pf *pf);
+void enetc_msg_handle_rxmsg(struct enetc_pf *pf, int mbox_id, u16 *status);
diff --git a/devices/enetc/enetc_ptp.c b/devices/enetc/enetc_ptp.c
deleted file mode 100644
index dabcdaf..0000000
--- a/devices/enetc/enetc_ptp.c
+++ /dev/null
@@ -1,163 +0,0 @@
-// SPDX-License-Identifier: (GPL-2.0+ OR BSD-3-Clause)
-/* Copyright 2019-2021 NXP */
-
-#include <linux/module.h>
-#include <linux/of.h>
-#include <linux/fsl/ptp_qoriq.h>
-
-#include "enetc.h"
-
-int enetc_phc_index = -1;
-EXPORT_SYMBOL(enetc_phc_index);
-
-static struct ptp_vclock_cc ptp_qoriq_vclock_cc = {
-	.cc.read		= ptp_qoriq_clock_read,
-	.cc.mask		= CYCLECOUNTER_MASK(64),
-	.cc.shift		= 28,
-	.cc.mult		= (1 << 28),
-	.refresh_interval	= (HZ * 60),
-	.mult_factor		= (1 << 6),
-	.div_factor		= 15625,
-};
-
-static struct ptp_clock_info enetc_ptp_caps = {
-	.owner		= THIS_MODULE,
-	.name		= "ENETC PTP clock",
-	.max_adj	= 512000,
-	.n_alarm	= 0,
-	.n_ext_ts	= 2,
-	.n_per_out	= 0,
-	.n_pins		= 0,
-	.pps		= 1,
-	.adjfine	= ptp_qoriq_adjfine,
-	.adjtime	= ptp_qoriq_adjtime,
-	.gettime64	= ptp_qoriq_gettime,
-	.settime64	= ptp_qoriq_settime,
-	.enable		= ptp_qoriq_enable,
-	.vclock_cc	= &ptp_qoriq_vclock_cc,
-};
-
-static int enetc_ptp_probe(struct pci_dev *pdev,
-			   const struct pci_device_id *ent)
-{
-	struct ptp_qoriq *ptp_qoriq;
-	void __iomem *base;
-	int err, len, n;
-
-	if (pdev->dev.of_node && !of_device_is_available(pdev->dev.of_node)) {
-		dev_info(&pdev->dev, "device is disabled, skipping\n");
-		return -ENODEV;
-	}
-
-	err = pci_enable_device_mem(pdev);
-	if (err) {
-		dev_err(&pdev->dev, "device enable failed\n");
-		return err;
-	}
-
-	/* set up for high or low dma */
-	err = dma_set_mask_and_coherent(&pdev->dev, DMA_BIT_MASK(64));
-	if (err) {
-		err = dma_set_mask_and_coherent(&pdev->dev, DMA_BIT_MASK(32));
-		if (err) {
-			dev_err(&pdev->dev,
-				"DMA configuration failed: 0x%x\n", err);
-			goto err_dma;
-		}
-	}
-
-	err = pci_request_mem_regions(pdev, KBUILD_MODNAME);
-	if (err) {
-		dev_err(&pdev->dev, "pci_request_regions failed err=%d\n", err);
-		goto err_pci_mem_reg;
-	}
-
-	pci_set_master(pdev);
-
-	ptp_qoriq = kzalloc(sizeof(*ptp_qoriq), GFP_KERNEL);
-	if (!ptp_qoriq) {
-		err = -ENOMEM;
-		goto err_alloc_ptp;
-	}
-
-	len = pci_resource_len(pdev, ENETC_BAR_REGS);
-
-	base = ioremap(pci_resource_start(pdev, ENETC_BAR_REGS), len);
-	if (!base) {
-		err = -ENXIO;
-		dev_err(&pdev->dev, "ioremap() failed\n");
-		goto err_ioremap;
-	}
-
-	/* Allocate 1 interrupt */
-	n = pci_alloc_irq_vectors(pdev, 1, 1, PCI_IRQ_MSIX);
-	if (n != 1) {
-		err = -EPERM;
-		goto err_irq_vectors;
-	}
-
-	ptp_qoriq->irq = pci_irq_vector(pdev, 0);
-
-	err = request_irq(ptp_qoriq->irq, ptp_qoriq_isr, 0, DRIVER, ptp_qoriq);
-	if (err) {
-		dev_err(&pdev->dev, "request_irq() failed!\n");
-		goto err_irq;
-	}
-
-	ptp_qoriq->dev = &pdev->dev;
-
-	err = ptp_qoriq_init(ptp_qoriq, base, &enetc_ptp_caps);
-	if (err)
-		goto err_no_clock;
-
-	enetc_phc_index = ptp_qoriq->phc_index;
-	pci_set_drvdata(pdev, ptp_qoriq);
-
-	return 0;
-
-err_no_clock:
-	free_irq(ptp_qoriq->irq, ptp_qoriq);
-err_irq:
-	pci_free_irq_vectors(pdev);
-err_irq_vectors:
-	iounmap(base);
-err_ioremap:
-	kfree(ptp_qoriq);
-err_alloc_ptp:
-	pci_release_mem_regions(pdev);
-err_pci_mem_reg:
-err_dma:
-	pci_disable_device(pdev);
-
-	return err;
-}
-
-static void enetc_ptp_remove(struct pci_dev *pdev)
-{
-	struct ptp_qoriq *ptp_qoriq = pci_get_drvdata(pdev);
-
-	enetc_phc_index = -1;
-	ptp_qoriq_free(ptp_qoriq);
-	pci_free_irq_vectors(pdev);
-	kfree(ptp_qoriq);
-
-	pci_release_mem_regions(pdev);
-	pci_disable_device(pdev);
-}
-
-static const struct pci_device_id enetc_ptp_id_table[] = {
-	{ PCI_DEVICE(PCI_VENDOR_ID_FREESCALE, ENETC_DEV_ID_PTP) },
-	{ 0, } /* End of table. */
-};
-MODULE_DEVICE_TABLE(pci, enetc_ptp_id_table);
-
-static struct pci_driver enetc_ptp_driver = {
-	.name = KBUILD_MODNAME,
-	.id_table = enetc_ptp_id_table,
-	.probe = enetc_ptp_probe,
-	.remove = enetc_ptp_remove,
-};
-module_pci_driver(enetc_ptp_driver);
-
-MODULE_DESCRIPTION("ENETC PTP clock driver");
-MODULE_LICENSE("Dual BSD/GPL");
diff --git a/devices/enetc/enetc_qos.c b/devices/enetc/enetc_qos.c
new file mode 100644
index 0000000..dbceb99
--- /dev/null
+++ b/devices/enetc/enetc_qos.c
@@ -0,0 +1,1576 @@
+// SPDX-License-Identifier: (GPL-2.0+ OR BSD-3-Clause)
+/* Copyright 2019 NXP */
+
+#include "enetc.h"
+
+#include <net/pkt_sched.h>
+#include <linux/math64.h>
+#include <linux/refcount.h>
+#include <net/pkt_cls.h>
+#include <net/tc_act/tc_gate.h>
+
+static u16 enetc_get_max_gcl_len(struct enetc_hw *hw)
+{
+	return enetc_rd(hw, ENETC_QBV_PTGCAPR_OFFSET)
+		& ENETC_QBV_MAX_GCL_LEN_MASK;
+}
+
+void enetc_sched_speed_set(struct enetc_ndev_priv *priv, int speed)
+{
+	u32 old_speed = priv->speed;
+	u32 pspeed;
+
+	if (speed == old_speed)
+		return;
+
+	switch (speed) {
+	case SPEED_1000:
+		pspeed = ENETC_PMR_PSPEED_1000M;
+		break;
+	case SPEED_2500:
+		pspeed = ENETC_PMR_PSPEED_2500M;
+		break;
+	case SPEED_100:
+		pspeed = ENETC_PMR_PSPEED_100M;
+		break;
+	case SPEED_10:
+	default:
+		pspeed = ENETC_PMR_PSPEED_10M;
+	}
+
+	priv->speed = speed;
+	enetc_port_wr(&priv->si->hw, ENETC_PMR,
+		      (enetc_port_rd(&priv->si->hw, ENETC_PMR)
+		      & (~ENETC_PMR_PSPEED_MASK))
+		      | pspeed);
+}
+
+static int enetc_setup_taprio(struct net_device *ndev,
+			      struct tc_taprio_qopt_offload *admin_conf)
+{
+	struct enetc_ndev_priv *priv = netdev_priv(ndev);
+	struct enetc_cbd cbd = {.cmd = 0};
+	struct tgs_gcl_conf *gcl_config;
+	struct tgs_gcl_data *gcl_data;
+	struct gce *gce;
+	dma_addr_t dma;
+	u16 data_size;
+	u16 gcl_len;
+	u32 tge;
+	int err;
+	int i;
+
+	if (admin_conf->num_entries > enetc_get_max_gcl_len(&priv->si->hw))
+		return -EINVAL;
+	gcl_len = admin_conf->num_entries;
+
+	tge = enetc_rd(&priv->si->hw, ENETC_QBV_PTGCR_OFFSET);
+	if (!admin_conf->enable) {
+		enetc_wr(&priv->si->hw,
+			 ENETC_QBV_PTGCR_OFFSET,
+			 tge & (~ENETC_QBV_TGE));
+		return 0;
+	}
+
+	if (admin_conf->cycle_time > U32_MAX ||
+	    admin_conf->cycle_time_extension > U32_MAX)
+		return -EINVAL;
+
+	/* Configure the (administrative) gate control list using the
+	 * control BD descriptor.
+	 */
+	gcl_config = &cbd.gcl_conf;
+
+	data_size = struct_size(gcl_data, entry, gcl_len);
+	gcl_data = kzalloc(data_size, __GFP_DMA | GFP_KERNEL);
+	if (!gcl_data)
+		return -ENOMEM;
+
+	gce = (struct gce *)(gcl_data + 1);
+
+	/* Set all gates open as default */
+	gcl_config->atc = 0xff;
+	gcl_config->acl_len = cpu_to_le16(gcl_len);
+
+	gcl_data->btl = cpu_to_le32(lower_32_bits(admin_conf->base_time));
+	gcl_data->bth = cpu_to_le32(upper_32_bits(admin_conf->base_time));
+	gcl_data->ct = cpu_to_le32(admin_conf->cycle_time);
+	gcl_data->cte = cpu_to_le32(admin_conf->cycle_time_extension);
+
+	for (i = 0; i < gcl_len; i++) {
+		struct tc_taprio_sched_entry *temp_entry;
+		struct gce *temp_gce = gce + i;
+
+		temp_entry = &admin_conf->entries[i];
+
+		temp_gce->gate = (u8)temp_entry->gate_mask;
+		temp_gce->period = cpu_to_le32(temp_entry->interval);
+	}
+
+	cbd.length = cpu_to_le16(data_size);
+	cbd.status_flags = 0;
+
+	dma = dma_map_single(&priv->si->pdev->dev, gcl_data,
+			     data_size, DMA_TO_DEVICE);
+	if (dma_mapping_error(&priv->si->pdev->dev, dma)) {
+		netdev_err(priv->si->ndev, "DMA mapping failed!\n");
+		kfree(gcl_data);
+		return -ENOMEM;
+	}
+
+	cbd.addr[0] = lower_32_bits(dma);
+	cbd.addr[1] = upper_32_bits(dma);
+	cbd.cls = BDCR_CMD_PORT_GCL;
+	cbd.status_flags = 0;
+
+	enetc_wr(&priv->si->hw, ENETC_QBV_PTGCR_OFFSET,
+		 tge | ENETC_QBV_TGE);
+
+	err = enetc_send_cmd(priv->si, &cbd);
+	if (err)
+		enetc_wr(&priv->si->hw,
+			 ENETC_QBV_PTGCR_OFFSET,
+			 tge & (~ENETC_QBV_TGE));
+
+	dma_unmap_single(&priv->si->pdev->dev, dma, data_size, DMA_TO_DEVICE);
+	kfree(gcl_data);
+
+	return err;
+}
+
+int enetc_setup_tc_taprio(struct net_device *ndev, void *type_data)
+{
+	struct tc_taprio_qopt_offload *taprio = type_data;
+	struct enetc_ndev_priv *priv = netdev_priv(ndev);
+	int err;
+	int i;
+
+	/* TSD and Qbv are mutually exclusive in hardware */
+	for (i = 0; i < priv->num_tx_rings; i++)
+		if (priv->tx_ring[i]->tsd_enable)
+			return -EBUSY;
+
+	for (i = 0; i < priv->num_tx_rings; i++)
+		enetc_set_bdr_prio(&priv->si->hw,
+				   priv->tx_ring[i]->index,
+				   taprio->enable ? i : 0);
+
+	err = enetc_setup_taprio(ndev, taprio);
+
+	if (err)
+		for (i = 0; i < priv->num_tx_rings; i++)
+			enetc_set_bdr_prio(&priv->si->hw,
+					   priv->tx_ring[i]->index,
+					   taprio->enable ? 0 : i);
+
+	return err;
+}
+
+static u32 enetc_get_cbs_enable(struct enetc_hw *hw, u8 tc)
+{
+	return enetc_port_rd(hw, ENETC_PTCCBSR0(tc)) & ENETC_CBSE;
+}
+
+static u8 enetc_get_cbs_bw(struct enetc_hw *hw, u8 tc)
+{
+	return enetc_port_rd(hw, ENETC_PTCCBSR0(tc)) & ENETC_CBS_BW_MASK;
+}
+
+int enetc_setup_tc_cbs(struct net_device *ndev, void *type_data)
+{
+	struct enetc_ndev_priv *priv = netdev_priv(ndev);
+	struct tc_cbs_qopt_offload *cbs = type_data;
+	u32 port_transmit_rate = priv->speed;
+	u8 tc_nums = netdev_get_num_tc(ndev);
+	struct enetc_si *si = priv->si;
+	u32 hi_credit_bit, hi_credit_reg;
+	u32 max_interference_size;
+	u32 port_frame_max_size;
+	u8 tc = cbs->queue;
+	u8 prio_top, prio_next;
+	int bw_sum = 0;
+	u8 bw;
+
+	prio_top = netdev_get_prio_tc_map(ndev, tc_nums - 1);
+	prio_next = netdev_get_prio_tc_map(ndev, tc_nums - 2);
+
+	/* Support highest prio and second prio tc in cbs mode */
+	if (tc != prio_top && tc != prio_next)
+		return -EOPNOTSUPP;
+
+	if (!cbs->enable) {
+		/* Make sure the other TC that are numerically
+		 * lower than this TC have been disabled.
+		 */
+		if (tc == prio_top &&
+		    enetc_get_cbs_enable(&si->hw, prio_next)) {
+			dev_err(&ndev->dev,
+				"Disable TC%d before disable TC%d\n",
+				prio_next, tc);
+			return -EINVAL;
+		}
+
+		enetc_port_wr(&si->hw, ENETC_PTCCBSR1(tc), 0);
+		enetc_port_wr(&si->hw, ENETC_PTCCBSR0(tc), 0);
+
+		return 0;
+	}
+
+	if (cbs->idleslope - cbs->sendslope != port_transmit_rate * 1000L ||
+	    cbs->idleslope < 0 || cbs->sendslope > 0)
+		return -EOPNOTSUPP;
+
+	port_frame_max_size = ndev->mtu + VLAN_ETH_HLEN + ETH_FCS_LEN;
+
+	bw = cbs->idleslope / (port_transmit_rate * 10UL);
+
+	/* Make sure the other TC that are numerically
+	 * higher than this TC have been enabled.
+	 */
+	if (tc == prio_next) {
+		if (!enetc_get_cbs_enable(&si->hw, prio_top)) {
+			dev_err(&ndev->dev,
+				"Enable TC%d first before enable TC%d\n",
+				prio_top, prio_next);
+			return -EINVAL;
+		}
+		bw_sum += enetc_get_cbs_bw(&si->hw, prio_top);
+	}
+
+	if (bw_sum + bw >= 100) {
+		dev_err(&ndev->dev,
+			"The sum of all CBS Bandwidth can't exceed 100\n");
+		return -EINVAL;
+	}
+
+	enetc_port_rd(&si->hw, ENETC_PTCMSDUR(tc));
+
+	/* For top prio TC, the max_interfrence_size is maxSizedFrame.
+	 *
+	 * For next prio TC, the max_interfrence_size is calculated as below:
+	 *
+	 *      max_interference_size = M0 + Ma + Ra * M0 / (R0 - Ra)
+	 *
+	 *	- RA: idleSlope for AVB Class A
+	 *	- R0: port transmit rate
+	 *	- M0: maximum sized frame for the port
+	 *	- MA: maximum sized frame for AVB Class A
+	 */
+
+	if (tc == prio_top) {
+		max_interference_size = port_frame_max_size * 8;
+	} else {
+		u32 m0, ma, r0, ra;
+
+		m0 = port_frame_max_size * 8;
+		ma = enetc_port_rd(&si->hw, ENETC_PTCMSDUR(prio_top)) * 8;
+		ra = enetc_get_cbs_bw(&si->hw, prio_top) *
+			port_transmit_rate * 10000ULL;
+		r0 = port_transmit_rate * 1000000ULL;
+		max_interference_size = m0 + ma +
+			(u32)div_u64((u64)ra * m0, r0 - ra);
+	}
+
+	/* hiCredit bits calculate by:
+	 *
+	 * maxSizedFrame * (idleSlope/portTxRate)
+	 */
+	hi_credit_bit = max_interference_size * bw / 100;
+
+	/* hiCredit bits to hiCredit register need to calculated as:
+	 *
+	 * (enetClockFrequency / portTransmitRate) * 100
+	 */
+	hi_credit_reg = (u32)div_u64((ENETC_CLK * 100ULL) * hi_credit_bit,
+				     port_transmit_rate * 1000000ULL);
+
+	enetc_port_wr(&si->hw, ENETC_PTCCBSR1(tc), hi_credit_reg);
+
+	/* Set bw register and enable this traffic class */
+	enetc_port_wr(&si->hw, ENETC_PTCCBSR0(tc), bw | ENETC_CBSE);
+
+	return 0;
+}
+
+int enetc_setup_tc_txtime(struct net_device *ndev, void *type_data)
+{
+	struct enetc_ndev_priv *priv = netdev_priv(ndev);
+	struct tc_etf_qopt_offload *qopt = type_data;
+	u8 tc_nums = netdev_get_num_tc(ndev);
+	int tc;
+
+	if (!tc_nums)
+		return -EOPNOTSUPP;
+
+	tc = qopt->queue;
+
+	if (tc < 0 || tc >= priv->num_tx_rings)
+		return -EINVAL;
+
+	/* Do not support TXSTART and TX CSUM offload simutaniously */
+	if (ndev->features & NETIF_F_CSUM_MASK)
+		return -EBUSY;
+
+	/* TSD and Qbv are mutually exclusive in hardware */
+	if (enetc_rd(&priv->si->hw, ENETC_QBV_PTGCR_OFFSET) & ENETC_QBV_TGE)
+		return -EBUSY;
+
+	priv->tx_ring[tc]->tsd_enable = qopt->enable;
+	enetc_port_wr(&priv->si->hw, ENETC_PTCTSDR(tc),
+		      qopt->enable ? ENETC_TSDE : 0);
+
+	return 0;
+}
+
+enum streamid_type {
+	STREAMID_TYPE_RESERVED = 0,
+	STREAMID_TYPE_NULL,
+	STREAMID_TYPE_SMAC,
+};
+
+enum streamid_vlan_tagged {
+	STREAMID_VLAN_RESERVED = 0,
+	STREAMID_VLAN_TAGGED,
+	STREAMID_VLAN_UNTAGGED,
+	STREAMID_VLAN_ALL,
+};
+
+#define ENETC_PSFP_WILDCARD -1
+#define HANDLE_OFFSET 100
+
+enum forward_type {
+	FILTER_ACTION_TYPE_PSFP = BIT(0),
+	FILTER_ACTION_TYPE_ACL = BIT(1),
+	FILTER_ACTION_TYPE_BOTH = GENMASK(1, 0),
+};
+
+/* This is for limit output type for input actions */
+struct actions_fwd {
+	u64 actions;
+	u64 keys;	/* include the must needed keys */
+	enum forward_type output;
+};
+
+struct psfp_streamfilter_counters {
+	u64 matching_frames_count;
+	u64 passing_frames_count;
+	u64 not_passing_frames_count;
+	u64 passing_sdu_count;
+	u64 not_passing_sdu_count;
+	u64 red_frames_count;
+};
+
+struct enetc_streamid {
+	u32 index;
+	union {
+		u8 src_mac[6];
+		u8 dst_mac[6];
+	};
+	u8 filtertype;
+	u16 vid;
+	u8 tagged;
+	s32 handle;
+};
+
+struct enetc_psfp_filter {
+	u32 index;
+	s32 handle;
+	s8 prio;
+	u32 maxsdu;
+	u32 gate_id;
+	s32 meter_id;
+	refcount_t refcount;
+	struct hlist_node node;
+};
+
+struct enetc_psfp_gate {
+	u32 index;
+	s8 init_ipv;
+	u64 basetime;
+	u64 cycletime;
+	u64 cycletimext;
+	u32 num_entries;
+	refcount_t refcount;
+	struct hlist_node node;
+	struct action_gate_entry entries[];
+};
+
+/* Only enable the green color frame now
+ * Will add eir and ebs color blind, couple flag etc when
+ * policing action add more offloading parameters
+ */
+struct enetc_psfp_meter {
+	u32 index;
+	u32 cir;
+	u32 cbs;
+	refcount_t refcount;
+	struct hlist_node node;
+};
+
+#define ENETC_PSFP_FLAGS_FMI BIT(0)
+
+struct enetc_stream_filter {
+	struct enetc_streamid sid;
+	u32 sfi_index;
+	u32 sgi_index;
+	u32 flags;
+	u32 fmi_index;
+	struct flow_stats stats;
+	struct hlist_node node;
+};
+
+struct enetc_psfp {
+	unsigned long dev_bitmap;
+	unsigned long *psfp_sfi_bitmap;
+	struct hlist_head stream_list;
+	struct hlist_head psfp_filter_list;
+	struct hlist_head psfp_gate_list;
+	struct hlist_head psfp_meter_list;
+	spinlock_t psfp_lock; /* spinlock for the struct enetc_psfp r/w */
+};
+
+static struct actions_fwd enetc_act_fwd[] = {
+	{
+		BIT(FLOW_ACTION_GATE),
+		BIT(FLOW_DISSECTOR_KEY_ETH_ADDRS),
+		FILTER_ACTION_TYPE_PSFP
+	},
+	{
+		BIT(FLOW_ACTION_POLICE) |
+		BIT(FLOW_ACTION_GATE),
+		BIT(FLOW_DISSECTOR_KEY_ETH_ADDRS),
+		FILTER_ACTION_TYPE_PSFP
+	},
+	/* example for ACL actions */
+	{
+		BIT(FLOW_ACTION_DROP),
+		0,
+		FILTER_ACTION_TYPE_ACL
+	}
+};
+
+static struct enetc_psfp epsfp = {
+	.psfp_sfi_bitmap = NULL,
+};
+
+static LIST_HEAD(enetc_block_cb_list);
+
+static inline int enetc_get_port(struct enetc_ndev_priv *priv)
+{
+	return priv->si->pdev->devfn & 0x7;
+}
+
+/* Stream Identity Entry Set Descriptor */
+static int enetc_streamid_hw_set(struct enetc_ndev_priv *priv,
+				 struct enetc_streamid *sid,
+				 u8 enable)
+{
+	struct enetc_cbd cbd = {.cmd = 0};
+	struct streamid_data *si_data;
+	struct streamid_conf *si_conf;
+	u16 data_size;
+	dma_addr_t dma;
+	int err;
+
+	if (sid->index >= priv->psfp_cap.max_streamid)
+		return -EINVAL;
+
+	if (sid->filtertype != STREAMID_TYPE_NULL &&
+	    sid->filtertype != STREAMID_TYPE_SMAC)
+		return -EOPNOTSUPP;
+
+	/* Disable operation before enable */
+	cbd.index = cpu_to_le16((u16)sid->index);
+	cbd.cls = BDCR_CMD_STREAM_IDENTIFY;
+	cbd.status_flags = 0;
+
+	data_size = sizeof(struct streamid_data);
+	si_data = kzalloc(data_size, __GFP_DMA | GFP_KERNEL);
+	cbd.length = cpu_to_le16(data_size);
+
+	dma = dma_map_single(&priv->si->pdev->dev, si_data,
+			     data_size, DMA_FROM_DEVICE);
+	if (dma_mapping_error(&priv->si->pdev->dev, dma)) {
+		netdev_err(priv->si->ndev, "DMA mapping failed!\n");
+		kfree(si_data);
+		return -ENOMEM;
+	}
+
+	cbd.addr[0] = lower_32_bits(dma);
+	cbd.addr[1] = upper_32_bits(dma);
+	eth_broadcast_addr(si_data->dmac);
+	si_data->vid_vidm_tg =
+		cpu_to_le16(ENETC_CBDR_SID_VID_MASK
+			    + ((0x3 << 14) | ENETC_CBDR_SID_VIDM));
+
+	si_conf = &cbd.sid_set;
+	/* Only one port supported for one entry, set itself */
+	si_conf->iports = 1 << enetc_get_port(priv);
+	si_conf->id_type = 1;
+	si_conf->oui[2] = 0x0;
+	si_conf->oui[1] = 0x80;
+	si_conf->oui[0] = 0xC2;
+
+	err = enetc_send_cmd(priv->si, &cbd);
+	if (err)
+		return -EINVAL;
+
+	if (!enable) {
+		kfree(si_data);
+		return 0;
+	}
+
+	/* Enable the entry overwrite again incase space flushed by hardware */
+	memset(&cbd, 0, sizeof(cbd));
+
+	cbd.index = cpu_to_le16((u16)sid->index);
+	cbd.cmd = 0;
+	cbd.cls = BDCR_CMD_STREAM_IDENTIFY;
+	cbd.status_flags = 0;
+
+	si_conf->en = 0x80;
+	si_conf->stream_handle = cpu_to_le32(sid->handle);
+	si_conf->iports = 1 << enetc_get_port(priv);
+	si_conf->id_type = sid->filtertype;
+	si_conf->oui[2] = 0x0;
+	si_conf->oui[1] = 0x80;
+	si_conf->oui[0] = 0xC2;
+
+	memset(si_data, 0, data_size);
+
+	cbd.length = cpu_to_le16(data_size);
+
+	cbd.addr[0] = lower_32_bits(dma);
+	cbd.addr[1] = upper_32_bits(dma);
+
+	/* VIDM default to be 1.
+	 * VID Match. If set (b1) then the VID must match, otherwise
+	 * any VID is considered a match. VIDM setting is only used
+	 * when TG is set to b01.
+	 */
+	if (si_conf->id_type == STREAMID_TYPE_NULL) {
+		ether_addr_copy(si_data->dmac, sid->dst_mac);
+		si_data->vid_vidm_tg =
+		cpu_to_le16((sid->vid & ENETC_CBDR_SID_VID_MASK) +
+			    ((((u16)(sid->tagged) & 0x3) << 14)
+			     | ENETC_CBDR_SID_VIDM));
+	} else if (si_conf->id_type == STREAMID_TYPE_SMAC) {
+		ether_addr_copy(si_data->smac, sid->src_mac);
+		si_data->vid_vidm_tg =
+		cpu_to_le16((sid->vid & ENETC_CBDR_SID_VID_MASK) +
+			    ((((u16)(sid->tagged) & 0x3) << 14)
+			     | ENETC_CBDR_SID_VIDM));
+	}
+
+	err = enetc_send_cmd(priv->si, &cbd);
+	kfree(si_data);
+
+	return err;
+}
+
+/* Stream Filter Instance Set Descriptor */
+static int enetc_streamfilter_hw_set(struct enetc_ndev_priv *priv,
+				     struct enetc_psfp_filter *sfi,
+				     u8 enable)
+{
+	struct enetc_cbd cbd = {.cmd = 0};
+	struct sfi_conf *sfi_config;
+
+	cbd.index = cpu_to_le16(sfi->index);
+	cbd.cls = BDCR_CMD_STREAM_FILTER;
+	cbd.status_flags = 0x80;
+	cbd.length = cpu_to_le16(1);
+
+	sfi_config = &cbd.sfi_conf;
+	if (!enable)
+		goto exit;
+
+	sfi_config->en = 0x80;
+
+	if (sfi->handle >= 0) {
+		sfi_config->stream_handle =
+			cpu_to_le32(sfi->handle);
+		sfi_config->sthm |= 0x80;
+	}
+
+	sfi_config->sg_inst_table_index = cpu_to_le16(sfi->gate_id);
+	sfi_config->input_ports = 1 << enetc_get_port(priv);
+
+	/* The priority value which may be matched against the
+	 * frame’s priority value to determine a match for this entry.
+	 */
+	if (sfi->prio >= 0)
+		sfi_config->multi |= (sfi->prio & 0x7) | 0x8;
+
+	/* Filter Type. Identifies the contents of the MSDU/FM_INST_INDEX
+	 * field as being either an MSDU value or an index into the Flow
+	 * Meter Instance table.
+	 */
+	if (sfi->maxsdu) {
+		sfi_config->msdu =
+		cpu_to_le16(sfi->maxsdu);
+		sfi_config->multi |= 0x40;
+	}
+
+	if (sfi->meter_id >= 0) {
+		sfi_config->fm_inst_table_index = cpu_to_le16(sfi->meter_id);
+		sfi_config->multi |= 0x80;
+	}
+
+exit:
+	return enetc_send_cmd(priv->si, &cbd);
+}
+
+static int enetc_streamcounter_hw_get(struct enetc_ndev_priv *priv,
+				      u32 index,
+				      struct psfp_streamfilter_counters *cnt)
+{
+	struct enetc_cbd cbd = { .cmd = 2 };
+	struct sfi_counter_data *data_buf;
+	dma_addr_t dma;
+	u16 data_size;
+	int err;
+
+	cbd.index = cpu_to_le16((u16)index);
+	cbd.cmd = 2;
+	cbd.cls = BDCR_CMD_STREAM_FILTER;
+	cbd.status_flags = 0;
+
+	data_size = sizeof(struct sfi_counter_data);
+	data_buf = kzalloc(data_size, __GFP_DMA | GFP_KERNEL);
+	if (!data_buf)
+		return -ENOMEM;
+
+	dma = dma_map_single(&priv->si->pdev->dev, data_buf,
+			     data_size, DMA_FROM_DEVICE);
+	if (dma_mapping_error(&priv->si->pdev->dev, dma)) {
+		netdev_err(priv->si->ndev, "DMA mapping failed!\n");
+		err = -ENOMEM;
+		goto exit;
+	}
+	cbd.addr[0] = lower_32_bits(dma);
+	cbd.addr[1] = upper_32_bits(dma);
+
+	cbd.length = cpu_to_le16(data_size);
+
+	err = enetc_send_cmd(priv->si, &cbd);
+	if (err)
+		goto exit;
+
+	cnt->matching_frames_count =
+			((u64)le32_to_cpu(data_buf->matchh) << 32)
+			+ data_buf->matchl;
+
+	cnt->not_passing_sdu_count =
+			((u64)le32_to_cpu(data_buf->msdu_droph) << 32)
+			+ data_buf->msdu_dropl;
+
+	cnt->passing_sdu_count = cnt->matching_frames_count
+				- cnt->not_passing_sdu_count;
+
+	cnt->not_passing_frames_count =
+		((u64)le32_to_cpu(data_buf->stream_gate_droph) << 32)
+		+ le32_to_cpu(data_buf->stream_gate_dropl);
+
+	cnt->passing_frames_count = cnt->matching_frames_count
+				- cnt->not_passing_sdu_count
+				- cnt->not_passing_frames_count;
+
+	cnt->red_frames_count =
+		((u64)le32_to_cpu(data_buf->flow_meter_droph) << 32)
+		+ le32_to_cpu(data_buf->flow_meter_dropl);
+
+exit:
+	kfree(data_buf);
+	return err;
+}
+
+static u64 get_ptp_now(struct enetc_hw *hw)
+{
+	u64 now_lo, now_hi, now;
+
+	now_lo = enetc_rd(hw, ENETC_SICTR0);
+	now_hi = enetc_rd(hw, ENETC_SICTR1);
+	now = now_lo | now_hi << 32;
+
+	return now;
+}
+
+static int get_start_ns(u64 now, u64 cycle, u64 *start)
+{
+	u64 n;
+
+	if (!cycle)
+		return -EFAULT;
+
+	n = div64_u64(now, cycle);
+
+	*start = (n + 1) * cycle;
+
+	return 0;
+}
+
+/* Stream Gate Instance Set Descriptor */
+static int enetc_streamgate_hw_set(struct enetc_ndev_priv *priv,
+				   struct enetc_psfp_gate *sgi,
+				   u8 enable)
+{
+	struct enetc_cbd cbd = { .cmd = 0 };
+	struct sgi_table *sgi_config;
+	struct sgcl_conf *sgcl_config;
+	struct sgcl_data *sgcl_data;
+	struct sgce *sgce;
+	dma_addr_t dma;
+	u16 data_size;
+	int err, i;
+	u64 now;
+
+	cbd.index = cpu_to_le16(sgi->index);
+	cbd.cmd = 0;
+	cbd.cls = BDCR_CMD_STREAM_GCL;
+	cbd.status_flags = 0x80;
+
+	/* disable */
+	if (!enable)
+		return enetc_send_cmd(priv->si, &cbd);
+
+	if (!sgi->num_entries)
+		return 0;
+
+	if (sgi->num_entries > priv->psfp_cap.max_psfp_gatelist ||
+	    !sgi->cycletime)
+		return -EINVAL;
+
+	/* enable */
+	sgi_config = &cbd.sgi_table;
+
+	/* Keep open before gate list start */
+	sgi_config->ocgtst = 0x80;
+
+	sgi_config->oipv = (sgi->init_ipv < 0) ?
+				0x0 : ((sgi->init_ipv & 0x7) | 0x8);
+
+	sgi_config->en = 0x80;
+
+	/* Basic config */
+	err = enetc_send_cmd(priv->si, &cbd);
+	if (err)
+		return -EINVAL;
+
+	memset(&cbd, 0, sizeof(cbd));
+
+	cbd.index = cpu_to_le16(sgi->index);
+	cbd.cmd = 1;
+	cbd.cls = BDCR_CMD_STREAM_GCL;
+	cbd.status_flags = 0;
+
+	sgcl_config = &cbd.sgcl_conf;
+
+	sgcl_config->acl_len = (sgi->num_entries - 1) & 0x3;
+
+	data_size = struct_size(sgcl_data, sgcl, sgi->num_entries);
+
+	sgcl_data = kzalloc(data_size, __GFP_DMA | GFP_KERNEL);
+	if (!sgcl_data)
+		return -ENOMEM;
+
+	cbd.length = cpu_to_le16(data_size);
+
+	dma = dma_map_single(&priv->si->pdev->dev,
+			     sgcl_data, data_size,
+			     DMA_FROM_DEVICE);
+	if (dma_mapping_error(&priv->si->pdev->dev, dma)) {
+		netdev_err(priv->si->ndev, "DMA mapping failed!\n");
+		kfree(sgcl_data);
+		return -ENOMEM;
+	}
+
+	cbd.addr[0] = lower_32_bits(dma);
+	cbd.addr[1] = upper_32_bits(dma);
+
+	sgce = &sgcl_data->sgcl[0];
+
+	sgcl_config->agtst = 0x80;
+
+	sgcl_data->ct = cpu_to_le32(sgi->cycletime);
+	sgcl_data->cte = cpu_to_le32(sgi->cycletimext);
+
+	if (sgi->init_ipv >= 0)
+		sgcl_config->aipv = (sgi->init_ipv & 0x7) | 0x8;
+
+	for (i = 0; i < sgi->num_entries; i++) {
+		struct action_gate_entry *from = &sgi->entries[i];
+		struct sgce *to = &sgce[i];
+
+		if (from->gate_state)
+			to->multi |= 0x10;
+
+		if (from->ipv >= 0)
+			to->multi |= ((from->ipv & 0x7) << 5) | 0x08;
+
+		if (from->maxoctets >= 0) {
+			to->multi |= 0x01;
+			to->msdu[0] = from->maxoctets & 0xFF;
+			to->msdu[1] = (from->maxoctets >> 8) & 0xFF;
+			to->msdu[2] = (from->maxoctets >> 16) & 0xFF;
+		}
+
+		to->interval = cpu_to_le32(from->interval);
+	}
+
+	/* If basetime is less than now, calculate start time */
+	now = get_ptp_now(&priv->si->hw);
+
+	if (sgi->basetime < now) {
+		u64 start;
+
+		err = get_start_ns(now, sgi->cycletime, &start);
+		if (err)
+			goto exit;
+		sgcl_data->btl = cpu_to_le32(lower_32_bits(start));
+		sgcl_data->bth = cpu_to_le32(upper_32_bits(start));
+	} else {
+		u32 hi, lo;
+
+		hi = upper_32_bits(sgi->basetime);
+		lo = lower_32_bits(sgi->basetime);
+		sgcl_data->bth = cpu_to_le32(hi);
+		sgcl_data->btl = cpu_to_le32(lo);
+	}
+
+	err = enetc_send_cmd(priv->si, &cbd);
+
+exit:
+	kfree(sgcl_data);
+
+	return err;
+}
+
+static int enetc_flowmeter_hw_set(struct enetc_ndev_priv *priv,
+				  struct enetc_psfp_meter *fmi,
+				  u8 enable)
+{
+	struct enetc_cbd cbd = { .cmd = 0 };
+	struct fmi_conf *fmi_config;
+	u64 temp = 0;
+
+	cbd.index = cpu_to_le16((u16)fmi->index);
+	cbd.cls = BDCR_CMD_FLOW_METER;
+	cbd.status_flags = 0x80;
+
+	if (!enable)
+		return enetc_send_cmd(priv->si, &cbd);
+
+	fmi_config = &cbd.fmi_conf;
+	fmi_config->en = 0x80;
+
+	if (fmi->cir) {
+		temp = (u64)8000 * fmi->cir;
+		temp = div_u64(temp, 3725);
+	}
+
+	fmi_config->cir = cpu_to_le32((u32)temp);
+	fmi_config->cbs = cpu_to_le32(fmi->cbs);
+
+	/* Default for eir ebs disable */
+	fmi_config->eir = 0;
+	fmi_config->ebs = 0;
+
+	/* Default:
+	 * mark red disable
+	 * drop on yellow disable
+	 * color mode disable
+	 * couple flag disable
+	 */
+	fmi_config->conf = 0;
+
+	return enetc_send_cmd(priv->si, &cbd);
+}
+
+static struct enetc_stream_filter *enetc_get_stream_by_index(u32 index)
+{
+	struct enetc_stream_filter *f;
+
+	hlist_for_each_entry(f, &epsfp.stream_list, node)
+		if (f->sid.index == index)
+			return f;
+
+	return NULL;
+}
+
+static struct enetc_psfp_gate *enetc_get_gate_by_index(u32 index)
+{
+	struct enetc_psfp_gate *g;
+
+	hlist_for_each_entry(g, &epsfp.psfp_gate_list, node)
+		if (g->index == index)
+			return g;
+
+	return NULL;
+}
+
+static struct enetc_psfp_filter *enetc_get_filter_by_index(u32 index)
+{
+	struct enetc_psfp_filter *s;
+
+	hlist_for_each_entry(s, &epsfp.psfp_filter_list, node)
+		if (s->index == index)
+			return s;
+
+	return NULL;
+}
+
+static struct enetc_psfp_meter *enetc_get_meter_by_index(u32 index)
+{
+	struct enetc_psfp_meter *m;
+
+	hlist_for_each_entry(m, &epsfp.psfp_meter_list, node)
+		if (m->index == index)
+			return m;
+
+	return NULL;
+}
+
+static struct enetc_psfp_filter
+	*enetc_psfp_check_sfi(struct enetc_psfp_filter *sfi)
+{
+	struct enetc_psfp_filter *s;
+
+	hlist_for_each_entry(s, &epsfp.psfp_filter_list, node)
+		if (s->gate_id == sfi->gate_id &&
+		    s->prio == sfi->prio &&
+		    s->maxsdu == sfi->maxsdu &&
+		    s->meter_id == sfi->meter_id)
+			return s;
+
+	return NULL;
+}
+
+static int enetc_get_free_index(struct enetc_ndev_priv *priv)
+{
+	u32 max_size = priv->psfp_cap.max_psfp_filter;
+	unsigned long index;
+
+	index = find_first_zero_bit(epsfp.psfp_sfi_bitmap, max_size);
+	if (index == max_size)
+		return -1;
+
+	return index;
+}
+
+static void stream_filter_unref(struct enetc_ndev_priv *priv, u32 index)
+{
+	struct enetc_psfp_filter *sfi;
+	u8 z;
+
+	sfi = enetc_get_filter_by_index(index);
+	WARN_ON(!sfi);
+	z = refcount_dec_and_test(&sfi->refcount);
+
+	if (z) {
+		enetc_streamfilter_hw_set(priv, sfi, false);
+		hlist_del(&sfi->node);
+		kfree(sfi);
+		clear_bit(index, epsfp.psfp_sfi_bitmap);
+	}
+}
+
+static void stream_gate_unref(struct enetc_ndev_priv *priv, u32 index)
+{
+	struct enetc_psfp_gate *sgi;
+	u8 z;
+
+	sgi = enetc_get_gate_by_index(index);
+	WARN_ON(!sgi);
+	z = refcount_dec_and_test(&sgi->refcount);
+	if (z) {
+		enetc_streamgate_hw_set(priv, sgi, false);
+		hlist_del(&sgi->node);
+		kfree(sgi);
+	}
+}
+
+static void flow_meter_unref(struct enetc_ndev_priv *priv, u32 index)
+{
+	struct enetc_psfp_meter *fmi;
+	u8 z;
+
+	fmi = enetc_get_meter_by_index(index);
+	WARN_ON(!fmi);
+	z = refcount_dec_and_test(&fmi->refcount);
+	if (z) {
+		enetc_flowmeter_hw_set(priv, fmi, false);
+		hlist_del(&fmi->node);
+		kfree(fmi);
+	}
+}
+
+static void remove_one_chain(struct enetc_ndev_priv *priv,
+			     struct enetc_stream_filter *filter)
+{
+	if (filter->flags & ENETC_PSFP_FLAGS_FMI)
+		flow_meter_unref(priv, filter->fmi_index);
+
+	stream_gate_unref(priv, filter->sgi_index);
+	stream_filter_unref(priv, filter->sfi_index);
+
+	hlist_del(&filter->node);
+	kfree(filter);
+}
+
+static int enetc_psfp_hw_set(struct enetc_ndev_priv *priv,
+			     struct enetc_streamid *sid,
+			     struct enetc_psfp_filter *sfi,
+			     struct enetc_psfp_gate *sgi,
+			     struct enetc_psfp_meter *fmi)
+{
+	int err;
+
+	err = enetc_streamid_hw_set(priv, sid, true);
+	if (err)
+		return err;
+
+	if (sfi) {
+		err = enetc_streamfilter_hw_set(priv, sfi, true);
+		if (err)
+			goto revert_sid;
+	}
+
+	err = enetc_streamgate_hw_set(priv, sgi, true);
+	if (err)
+		goto revert_sfi;
+
+	if (fmi) {
+		err = enetc_flowmeter_hw_set(priv, fmi, true);
+		if (err)
+			goto revert_sgi;
+	}
+
+	return 0;
+
+revert_sgi:
+	enetc_streamgate_hw_set(priv, sgi, false);
+revert_sfi:
+	if (sfi)
+		enetc_streamfilter_hw_set(priv, sfi, false);
+revert_sid:
+	enetc_streamid_hw_set(priv, sid, false);
+	return err;
+}
+
+static struct actions_fwd *enetc_check_flow_actions(u64 acts,
+						    unsigned int inputkeys)
+{
+	int i;
+
+	for (i = 0; i < ARRAY_SIZE(enetc_act_fwd); i++)
+		if (acts == enetc_act_fwd[i].actions &&
+		    inputkeys & enetc_act_fwd[i].keys)
+			return &enetc_act_fwd[i];
+
+	return NULL;
+}
+
+static int enetc_psfp_parse_clsflower(struct enetc_ndev_priv *priv,
+				      struct flow_cls_offload *f)
+{
+	struct flow_action_entry *entryg = NULL, *entryp = NULL;
+	struct flow_rule *rule = flow_cls_offload_flow_rule(f);
+	struct netlink_ext_ack *extack = f->common.extack;
+	struct enetc_stream_filter *filter, *old_filter;
+	struct enetc_psfp_meter *fmi = NULL, *old_fmi;
+	struct enetc_psfp_filter *sfi, *old_sfi;
+	struct enetc_psfp_gate *sgi, *old_sgi;
+	struct flow_action_entry *entry;
+	struct action_gate_entry *e;
+	u8 sfi_overwrite = 0;
+	int entries_size;
+	int i, err;
+
+	if (f->common.chain_index >= priv->psfp_cap.max_streamid) {
+		NL_SET_ERR_MSG_MOD(extack, "No Stream identify resource!");
+		return -ENOSPC;
+	}
+
+	flow_action_for_each(i, entry, &rule->action)
+		if (entry->id == FLOW_ACTION_GATE)
+			entryg = entry;
+		else if (entry->id == FLOW_ACTION_POLICE)
+			entryp = entry;
+
+	/* Not support without gate action */
+	if (!entryg)
+		return -EINVAL;
+
+	filter = kzalloc(sizeof(*filter), GFP_KERNEL);
+	if (!filter)
+		return -ENOMEM;
+
+	filter->sid.index = f->common.chain_index;
+
+	if (flow_rule_match_key(rule, FLOW_DISSECTOR_KEY_ETH_ADDRS)) {
+		struct flow_match_eth_addrs match;
+
+		flow_rule_match_eth_addrs(rule, &match);
+
+		if (!is_zero_ether_addr(match.mask->dst) &&
+		    !is_zero_ether_addr(match.mask->src)) {
+			NL_SET_ERR_MSG_MOD(extack,
+					   "Cannot match on both source and destination MAC");
+			err = -EINVAL;
+			goto free_filter;
+		}
+
+		if (!is_zero_ether_addr(match.mask->dst)) {
+			if (!is_broadcast_ether_addr(match.mask->dst)) {
+				NL_SET_ERR_MSG_MOD(extack,
+						   "Masked matching on destination MAC not supported");
+				err = -EINVAL;
+				goto free_filter;
+			}
+			ether_addr_copy(filter->sid.dst_mac, match.key->dst);
+			filter->sid.filtertype = STREAMID_TYPE_NULL;
+		}
+
+		if (!is_zero_ether_addr(match.mask->src)) {
+			if (!is_broadcast_ether_addr(match.mask->src)) {
+				NL_SET_ERR_MSG_MOD(extack,
+						   "Masked matching on source MAC not supported");
+				err = -EINVAL;
+				goto free_filter;
+			}
+			ether_addr_copy(filter->sid.src_mac, match.key->src);
+			filter->sid.filtertype = STREAMID_TYPE_SMAC;
+		}
+	} else {
+		NL_SET_ERR_MSG_MOD(extack, "Unsupported, must include ETH_ADDRS");
+		err = -EINVAL;
+		goto free_filter;
+	}
+
+	if (flow_rule_match_key(rule, FLOW_DISSECTOR_KEY_VLAN)) {
+		struct flow_match_vlan match;
+
+		flow_rule_match_vlan(rule, &match);
+		if (match.mask->vlan_priority) {
+			if (match.mask->vlan_priority !=
+			    (VLAN_PRIO_MASK >> VLAN_PRIO_SHIFT)) {
+				NL_SET_ERR_MSG_MOD(extack, "Only full mask is supported for VLAN priority");
+				err = -EINVAL;
+				goto free_filter;
+			}
+		}
+
+		if (match.mask->vlan_id) {
+			if (match.mask->vlan_id != VLAN_VID_MASK) {
+				NL_SET_ERR_MSG_MOD(extack, "Only full mask is supported for VLAN id");
+				err = -EINVAL;
+				goto free_filter;
+			}
+
+			filter->sid.vid = match.key->vlan_id;
+			if (!filter->sid.vid)
+				filter->sid.tagged = STREAMID_VLAN_UNTAGGED;
+			else
+				filter->sid.tagged = STREAMID_VLAN_TAGGED;
+		}
+	} else {
+		filter->sid.tagged = STREAMID_VLAN_ALL;
+	}
+
+	/* parsing gate action */
+	if (entryg->gate.index >= priv->psfp_cap.max_psfp_gate) {
+		NL_SET_ERR_MSG_MOD(extack, "No Stream Gate resource!");
+		err = -ENOSPC;
+		goto free_filter;
+	}
+
+	if (entryg->gate.num_entries >= priv->psfp_cap.max_psfp_gatelist) {
+		NL_SET_ERR_MSG_MOD(extack, "No Stream Gate resource!");
+		err = -ENOSPC;
+		goto free_filter;
+	}
+
+	entries_size = struct_size(sgi, entries, entryg->gate.num_entries);
+	sgi = kzalloc(entries_size, GFP_KERNEL);
+	if (!sgi) {
+		err = -ENOMEM;
+		goto free_filter;
+	}
+
+	refcount_set(&sgi->refcount, 1);
+	sgi->index = entryg->gate.index;
+	sgi->init_ipv = entryg->gate.prio;
+	sgi->basetime = entryg->gate.basetime;
+	sgi->cycletime = entryg->gate.cycletime;
+	sgi->num_entries = entryg->gate.num_entries;
+
+	e = sgi->entries;
+	for (i = 0; i < entryg->gate.num_entries; i++) {
+		e[i].gate_state = entryg->gate.entries[i].gate_state;
+		e[i].interval = entryg->gate.entries[i].interval;
+		e[i].ipv = entryg->gate.entries[i].ipv;
+		e[i].maxoctets = entryg->gate.entries[i].maxoctets;
+	}
+
+	filter->sgi_index = sgi->index;
+
+	sfi = kzalloc(sizeof(*sfi), GFP_KERNEL);
+	if (!sfi) {
+		err = -ENOMEM;
+		goto free_gate;
+	}
+
+	refcount_set(&sfi->refcount, 1);
+	sfi->gate_id = sgi->index;
+	sfi->meter_id = ENETC_PSFP_WILDCARD;
+
+	/* Flow meter and max frame size */
+	if (entryp) {
+		if (entryp->police.burst) {
+			fmi = kzalloc(sizeof(*fmi), GFP_KERNEL);
+			if (!fmi) {
+				err = -ENOMEM;
+				goto free_sfi;
+			}
+			refcount_set(&fmi->refcount, 1);
+			fmi->cir = entryp->police.rate_bytes_ps;
+			fmi->cbs = entryp->police.burst;
+			fmi->index = entryp->police.index;
+			filter->flags |= ENETC_PSFP_FLAGS_FMI;
+			filter->fmi_index = fmi->index;
+			sfi->meter_id = fmi->index;
+		}
+
+		if (entryp->police.mtu)
+			sfi->maxsdu = entryp->police.mtu;
+	}
+
+	/* prio ref the filter prio */
+	if (f->common.prio && f->common.prio <= BIT(3))
+		sfi->prio = f->common.prio - 1;
+	else
+		sfi->prio = ENETC_PSFP_WILDCARD;
+
+	old_sfi = enetc_psfp_check_sfi(sfi);
+	if (!old_sfi) {
+		int index;
+
+		index = enetc_get_free_index(priv);
+		if (sfi->handle < 0) {
+			NL_SET_ERR_MSG_MOD(extack, "No Stream Filter resource!");
+			err = -ENOSPC;
+			goto free_fmi;
+		}
+
+		sfi->index = index;
+		sfi->handle = index + HANDLE_OFFSET;
+		/* Update the stream filter handle also */
+		filter->sid.handle = sfi->handle;
+		filter->sfi_index = sfi->index;
+		sfi_overwrite = 0;
+	} else {
+		filter->sfi_index = old_sfi->index;
+		filter->sid.handle = old_sfi->handle;
+		sfi_overwrite = 1;
+	}
+
+	err = enetc_psfp_hw_set(priv, &filter->sid,
+				sfi_overwrite ? NULL : sfi, sgi, fmi);
+	if (err)
+		goto free_fmi;
+
+	spin_lock(&epsfp.psfp_lock);
+	if (filter->flags & ENETC_PSFP_FLAGS_FMI) {
+		old_fmi = enetc_get_meter_by_index(filter->fmi_index);
+		if (old_fmi) {
+			fmi->refcount = old_fmi->refcount;
+			refcount_set(&fmi->refcount,
+				     refcount_read(&old_fmi->refcount) + 1);
+			hlist_del(&old_fmi->node);
+			kfree(old_fmi);
+		}
+		hlist_add_head(&fmi->node, &epsfp.psfp_meter_list);
+	}
+
+	/* Remove the old node if exist and update with a new node */
+	old_sgi = enetc_get_gate_by_index(filter->sgi_index);
+	if (old_sgi) {
+		refcount_set(&sgi->refcount,
+			     refcount_read(&old_sgi->refcount) + 1);
+		hlist_del(&old_sgi->node);
+		kfree(old_sgi);
+	}
+
+	hlist_add_head(&sgi->node, &epsfp.psfp_gate_list);
+
+	if (!old_sfi) {
+		hlist_add_head(&sfi->node, &epsfp.psfp_filter_list);
+		set_bit(sfi->index, epsfp.psfp_sfi_bitmap);
+	} else {
+		kfree(sfi);
+		refcount_inc(&old_sfi->refcount);
+	}
+
+	old_filter = enetc_get_stream_by_index(filter->sid.index);
+	if (old_filter)
+		remove_one_chain(priv, old_filter);
+
+	filter->stats.lastused = jiffies;
+	hlist_add_head(&filter->node, &epsfp.stream_list);
+
+	spin_unlock(&epsfp.psfp_lock);
+
+	return 0;
+
+free_fmi:
+	kfree(fmi);
+free_sfi:
+	kfree(sfi);
+free_gate:
+	kfree(sgi);
+free_filter:
+	kfree(filter);
+
+	return err;
+}
+
+static int enetc_config_clsflower(struct enetc_ndev_priv *priv,
+				  struct flow_cls_offload *cls_flower)
+{
+	struct flow_rule *rule = flow_cls_offload_flow_rule(cls_flower);
+	struct netlink_ext_ack *extack = cls_flower->common.extack;
+	struct flow_dissector *dissector = rule->match.dissector;
+	struct flow_action *action = &rule->action;
+	struct flow_action_entry *entry;
+	struct actions_fwd *fwd;
+	u64 actions = 0;
+	int i, err;
+
+	if (!flow_action_has_entries(action)) {
+		NL_SET_ERR_MSG_MOD(extack, "At least one action is needed");
+		return -EINVAL;
+	}
+
+	flow_action_for_each(i, entry, action)
+		actions |= BIT(entry->id);
+
+	fwd = enetc_check_flow_actions(actions, dissector->used_keys);
+	if (!fwd) {
+		NL_SET_ERR_MSG_MOD(extack, "Unsupported filter type!");
+		return -EOPNOTSUPP;
+	}
+
+	if (fwd->output & FILTER_ACTION_TYPE_PSFP) {
+		err = enetc_psfp_parse_clsflower(priv, cls_flower);
+		if (err) {
+			NL_SET_ERR_MSG_MOD(extack, "Invalid PSFP inputs");
+			return err;
+		}
+	} else {
+		NL_SET_ERR_MSG_MOD(extack, "Unsupported actions");
+		return -EOPNOTSUPP;
+	}
+
+	return 0;
+}
+
+static int enetc_psfp_destroy_clsflower(struct enetc_ndev_priv *priv,
+					struct flow_cls_offload *f)
+{
+	struct enetc_stream_filter *filter;
+	struct netlink_ext_ack *extack = f->common.extack;
+	int err;
+
+	if (f->common.chain_index >= priv->psfp_cap.max_streamid) {
+		NL_SET_ERR_MSG_MOD(extack, "No Stream identify resource!");
+		return -ENOSPC;
+	}
+
+	filter = enetc_get_stream_by_index(f->common.chain_index);
+	if (!filter)
+		return -EINVAL;
+
+	err = enetc_streamid_hw_set(priv, &filter->sid, false);
+	if (err)
+		return err;
+
+	remove_one_chain(priv, filter);
+
+	return 0;
+}
+
+static int enetc_destroy_clsflower(struct enetc_ndev_priv *priv,
+				   struct flow_cls_offload *f)
+{
+	return enetc_psfp_destroy_clsflower(priv, f);
+}
+
+static int enetc_psfp_get_stats(struct enetc_ndev_priv *priv,
+				struct flow_cls_offload *f)
+{
+	struct psfp_streamfilter_counters counters = {};
+	struct enetc_stream_filter *filter;
+	struct flow_stats stats = {};
+	int err;
+
+	filter = enetc_get_stream_by_index(f->common.chain_index);
+	if (!filter)
+		return -EINVAL;
+
+	err = enetc_streamcounter_hw_get(priv, filter->sfi_index, &counters);
+	if (err)
+		return -EINVAL;
+
+	spin_lock(&epsfp.psfp_lock);
+	stats.pkts = counters.matching_frames_count +
+		     counters.not_passing_sdu_count -
+		     filter->stats.pkts;
+	stats.drops = counters.not_passing_frames_count +
+		      counters.not_passing_sdu_count +
+		      counters.red_frames_count -
+		      filter->stats.drops;
+	stats.lastused = filter->stats.lastused;
+	filter->stats.pkts += stats.pkts;
+	filter->stats.drops += stats.drops;
+	spin_unlock(&epsfp.psfp_lock);
+
+	flow_stats_update(&f->stats, 0x0, stats.pkts, stats.drops,
+			  stats.lastused, FLOW_ACTION_HW_STATS_DELAYED);
+
+	return 0;
+}
+
+static int enetc_setup_tc_cls_flower(struct enetc_ndev_priv *priv,
+				     struct flow_cls_offload *cls_flower)
+{
+	switch (cls_flower->command) {
+	case FLOW_CLS_REPLACE:
+		return enetc_config_clsflower(priv, cls_flower);
+	case FLOW_CLS_DESTROY:
+		return enetc_destroy_clsflower(priv, cls_flower);
+	case FLOW_CLS_STATS:
+		return enetc_psfp_get_stats(priv, cls_flower);
+	default:
+		return -EOPNOTSUPP;
+	}
+}
+
+static inline void clean_psfp_sfi_bitmap(void)
+{
+	bitmap_free(epsfp.psfp_sfi_bitmap);
+	epsfp.psfp_sfi_bitmap = NULL;
+}
+
+static void clean_stream_list(void)
+{
+	struct enetc_stream_filter *s;
+	struct hlist_node *tmp;
+
+	hlist_for_each_entry_safe(s, tmp, &epsfp.stream_list, node) {
+		hlist_del(&s->node);
+		kfree(s);
+	}
+}
+
+static void clean_sfi_list(void)
+{
+	struct enetc_psfp_filter *sfi;
+	struct hlist_node *tmp;
+
+	hlist_for_each_entry_safe(sfi, tmp, &epsfp.psfp_filter_list, node) {
+		hlist_del(&sfi->node);
+		kfree(sfi);
+	}
+}
+
+static void clean_sgi_list(void)
+{
+	struct enetc_psfp_gate *sgi;
+	struct hlist_node *tmp;
+
+	hlist_for_each_entry_safe(sgi, tmp, &epsfp.psfp_gate_list, node) {
+		hlist_del(&sgi->node);
+		kfree(sgi);
+	}
+}
+
+static void clean_psfp_all(void)
+{
+	/* Disable all list nodes and free all memory */
+	clean_sfi_list();
+	clean_sgi_list();
+	clean_stream_list();
+	epsfp.dev_bitmap = 0;
+	clean_psfp_sfi_bitmap();
+}
+
+int enetc_setup_tc_block_cb(enum tc_setup_type type, void *type_data,
+			    void *cb_priv)
+{
+	struct net_device *ndev = cb_priv;
+
+	if (!tc_can_offload(ndev))
+		return -EOPNOTSUPP;
+
+	switch (type) {
+	case TC_SETUP_CLSFLOWER:
+		return enetc_setup_tc_cls_flower(netdev_priv(ndev), type_data);
+	default:
+		return -EOPNOTSUPP;
+	}
+}
+
+int enetc_psfp_init(struct enetc_ndev_priv *priv)
+{
+	if (epsfp.psfp_sfi_bitmap)
+		return 0;
+
+	epsfp.psfp_sfi_bitmap = bitmap_zalloc(priv->psfp_cap.max_psfp_filter,
+					      GFP_KERNEL);
+	if (!epsfp.psfp_sfi_bitmap)
+		return -ENOMEM;
+
+	spin_lock_init(&epsfp.psfp_lock);
+
+	if (list_empty(&enetc_block_cb_list))
+		epsfp.dev_bitmap = 0;
+
+	return 0;
+}
+
+int enetc_psfp_clean(struct enetc_ndev_priv *priv)
+{
+	if (!list_empty(&enetc_block_cb_list))
+		return -EBUSY;
+
+	clean_psfp_all();
+
+	return 0;
+}
+
+int enetc_setup_tc_psfp(struct net_device *ndev, void *type_data)
+{
+	struct enetc_ndev_priv *priv = netdev_priv(ndev);
+	struct flow_block_offload *f = type_data;
+	int err;
+
+	err = flow_block_cb_setup_simple(f, &enetc_block_cb_list,
+					 enetc_setup_tc_block_cb,
+					 ndev, ndev, true);
+	if (err)
+		return err;
+
+	switch (f->command) {
+	case FLOW_BLOCK_BIND:
+		set_bit(enetc_get_port(priv), &epsfp.dev_bitmap);
+		break;
+	case FLOW_BLOCK_UNBIND:
+		clear_bit(enetc_get_port(priv), &epsfp.dev_bitmap);
+		if (!epsfp.dev_bitmap)
+			clean_psfp_all();
+		break;
+	}
+
+	return 0;
+}
diff --git a/devices/enetc/enetc_tsn.c b/devices/enetc/enetc_tsn.c
deleted file mode 100644
index cea239c..0000000
--- a/devices/enetc/enetc_tsn.c
+++ /dev/null
@@ -1,2010 +0,0 @@
-// SPDX-License-Identifier: (GPL-2.0+ OR BSD-3-Clause)
-/* Copyright 2017-2019 NXP */
-
-#ifdef CONFIG_ENETC_TSN
-#include "enetc.h"
-
-#include <net/tsn.h>
-#include <linux/module.h>
-#include <linux/irqflags.h>
-#include <linux/preempt.h>
-
-static int alloc_cbdr(struct enetc_si *si, struct enetc_cbd **curr_cbd)
-{
-	struct enetc_cbdr *ring = &si->cbd_ring;
-	int i;
-
-	i = ring->next_to_use;
-	*curr_cbd = ENETC_CBD(*ring, i);
-
-	memset(*curr_cbd, 0, sizeof(struct enetc_cbd));
-	return i;
-}
-
-/* Transmit the BD control ring by writing the pir register.
- * Update the counters maintained by software.
- */
-static int xmit_cbdr(struct enetc_si *si, int i)
-{
-	struct enetc_cbdr *ring = &si->cbd_ring;
-	struct enetc_cbd *dest_cbd;
-	int nc, timeout;
-
-	i = (i + 1) % ring->bd_count;
-
-	ring->next_to_use = i;
-	/* let H/W know BD ring has been updated */
-	enetc_wr_reg(ring->pir, i);
-
-	timeout = ENETC_CBDR_TIMEOUT;
-
-	do {
-		if (enetc_rd_reg(ring->cir) == i)
-			break;
-		usleep_range(10, 20);
-		timeout -= 10;
-	} while (timeout);
-
-	if (!timeout)
-		return -EBUSY;
-
-	nc = ring->next_to_clean;
-
-	while (enetc_rd_reg(ring->cir) != nc) {
-		dest_cbd = ENETC_CBD(*ring, nc);
-		if (dest_cbd->status_flags & ENETC_CBD_STATUS_MASK)
-			WARN_ON(1);
-
-		nc = (nc + 1) % ring->bd_count;
-	}
-
-	ring->next_to_clean = nc;
-
-	return 0;
-}
-
-static inline u64 get_current_time(struct enetc_si *si)
-{
-	u64 tmp = 0;
-
-	tmp = (u64)enetc_rd(&si->hw, ENETC_SICTR0);
-	return ((u64)enetc_rd(&si->hw, ENETC_SICTR1) << 32) + tmp;
-}
-
-/* Class 10: Flow Meter Instance Statistics Query Descriptor - Long Format */
-int enetc_qci_fmi_counters_get(struct net_device *ndev, u32 index,
-			       struct fmi_query_stat_resp *counters)
-{
-	struct enetc_cbd *cbdr;
-	struct fmi_query_stat_resp *fmi_data;
-	dma_addr_t dma;
-	u16 data_size, dma_size;
-	int curr_cbd;
-	struct enetc_ndev_priv *priv = netdev_priv(ndev);
-
-	curr_cbd = alloc_cbdr(priv->si, &cbdr);
-
-	cbdr->index = cpu_to_le16((u16)index);
-	cbdr->cmd = 2;
-	cbdr->cls = BDCR_CMD_FLOW_METER;
-	cbdr->status_flags = 0;
-
-	data_size = sizeof(struct fmi_query_stat_resp);
-
-	fmi_data = kzalloc(data_size, __GFP_DMA | GFP_KERNEL);
-	if (!fmi_data)
-		return -ENOMEM;
-
-	dma_size = cpu_to_le16(data_size);
-	cbdr->length = dma_size;
-
-	dma = dma_map_single(&priv->si->pdev->dev, fmi_data,
-			     data_size, DMA_FROM_DEVICE);
-	if (dma_mapping_error(&priv->si->pdev->dev, dma)) {
-		netdev_err(priv->si->ndev, "DMA mapping failed!\n");
-		kfree(fmi_data);
-		return -ENOMEM;
-	}
-	cbdr->addr[0] = lower_32_bits(dma);
-	cbdr->addr[1] = upper_32_bits(dma);
-
-	xmit_cbdr(priv->si, curr_cbd);
-
-	memcpy(counters, fmi_data, sizeof(struct fmi_query_stat_resp));
-
-	memset(cbdr, 0, sizeof(*cbdr));
-	kfree(fmi_data);
-	return 0;
-}
-
-u16 enetc_get_max_gcl_len(struct enetc_hw *hw)
-{
-	return (enetc_rd(hw, ENETC_QBV_PTGCAPR_OFFSET)
-		& ENETC_QBV_MAX_GCL_LEN_MASK);
-}
-
-void enetc_pspeed_set(struct enetc_ndev_priv *priv, int speed)
-{
-	u32 old_speed = priv->speed;
-	u32 pspeed;
-
-	if (speed == old_speed)
-		return;
-
-	switch (speed) {
-	case SPEED_1000:
-		pspeed = ENETC_PMR_PSPEED_1000M;
-		break;
-	case SPEED_2500:
-		pspeed = ENETC_PMR_PSPEED_2500M;
-		break;
-	case SPEED_100:
-		pspeed = ENETC_PMR_PSPEED_100M;
-		break;
-	case SPEED_10:
-	default:
-		pspeed = ENETC_PMR_PSPEED_10M;
-	}
-
-	priv->speed = speed;
-	enetc_port_wr(&priv->si->hw, ENETC_PMR,
-		      (enetc_port_rd(&priv->si->hw, ENETC_PMR)
-		      & (~ENETC_PMR_PSPEED_MASK))
-		      | pspeed);
-}
-
-/* CBD Class 5: Time Gated Scheduling Gate Control List configuration
- * Descriptor - Long Format
- */
-int enetc_qbv_set(struct net_device *ndev, struct tsn_qbv_conf *admin_conf)
-{
-	struct enetc_cbd *cbdr;
-	struct tgs_gcl_data *gcl_data;
-	struct tgs_gcl_conf *gcl_config;
-	struct gce *gce;
-	u16 gcl_len;
-	u16 data_size;
-	int i;
-	dma_addr_t dma;
-	int curr_cbd;
-	struct tsn_qbv_basic *admin_basic = &admin_conf->admin;
-	struct enetc_ndev_priv *priv = netdev_priv(ndev);
-	u32 temp;
-	u64 tempclock;
-	struct tsn_port *port;
-
-	port = tsn_get_port(ndev);
-	if (!port) {
-		netdev_err(priv->si->ndev, "TSN device not registered!\n");
-		return -ENODEV;
-	}
-
-	gcl_len = admin_basic->control_list_length;
-	if (gcl_len > enetc_get_max_gcl_len(&priv->si->hw))
-		return -EINVAL;
-
-	temp = enetc_rd(&priv->si->hw, ENETC_QBV_PTGCR_OFFSET);
-	if (admin_conf->gate_enabled && !(temp & ENETC_QBV_TGE)) {
-		enetc_wr(&priv->si->hw, ENETC_QBV_PTGCR_OFFSET,
-			 temp & (~ENETC_QBV_TGE));
-		usleep_range(10, 20);
-		enetc_wr(&priv->si->hw, ENETC_QBV_PTGCR_OFFSET,
-			 temp | ENETC_QBV_TGE);
-	} else if (!admin_conf->gate_enabled) {
-		enetc_wr(&priv->si->hw, ENETC_QBV_PTGCR_OFFSET,
-			 temp & (~ENETC_QBV_TGE));
-		memcpy(&port->nd.ntdata, admin_conf, sizeof(*admin_conf));
-		call_tsn_notifiers(TSN_QBV_CONFIGCHANGETIME_ARRIVE,
-				   ndev, &port->nd);
-		return 0;
-	}
-
-	/* Set the maximum frame size for each traffic class index
-	 * PTCaMSDUR[MAXSDU]. The maximum frame size cannot exceed
-	 * 9,600 bytes (0x2580). Frames that exceed the limit are
-	 * discarded.
-	 */
-	if (admin_conf->maxsdu) {
-		enetc_wr(&priv->si->hw, ENETC_PTC0MSDUR, admin_conf->maxsdu);
-		enetc_wr(&priv->si->hw, ENETC_PTC1MSDUR, admin_conf->maxsdu);
-		enetc_wr(&priv->si->hw, ENETC_PTC2MSDUR, admin_conf->maxsdu);
-		enetc_wr(&priv->si->hw, ENETC_PTC3MSDUR, admin_conf->maxsdu);
-		enetc_wr(&priv->si->hw, ENETC_PTC4MSDUR, admin_conf->maxsdu);
-		enetc_wr(&priv->si->hw, ENETC_PTC5MSDUR, admin_conf->maxsdu);
-		enetc_wr(&priv->si->hw, ENETC_PTC6MSDUR, admin_conf->maxsdu);
-		enetc_wr(&priv->si->hw, ENETC_PTC7MSDUR, admin_conf->maxsdu);
-	}
-
-	/* Configure the (administrative) gate control list using the
-	 * control BD descriptor.
-	 */
-	curr_cbd = alloc_cbdr(priv->si, &cbdr);
-
-	gcl_config = &cbdr->gcl_conf;
-
-	data_size = struct_size(gcl_data, entry, gcl_len);
-
-	gcl_data = kzalloc(data_size, __GFP_DMA | GFP_KERNEL);
-	if (!gcl_data)
-		return -ENOMEM;
-
-	gce = &gcl_data->entry[0];
-
-	gcl_config->atc = admin_basic->gate_states;
-	gcl_config->acl_len = cpu_to_le16(gcl_len);
-
-	if (!admin_basic->base_time) {
-		gcl_data->btl =
-			cpu_to_le32(enetc_rd(&priv->si->hw, ENETC_SICTR0));
-		gcl_data->bth =
-			cpu_to_le32(enetc_rd(&priv->si->hw, ENETC_SICTR1));
-	} else {
-		gcl_data->btl =
-			cpu_to_le32(lower_32_bits(admin_basic->base_time));
-		gcl_data->bth =
-			cpu_to_le32(upper_32_bits(admin_basic->base_time));
-	}
-
-	gcl_data->ct = cpu_to_le32(admin_basic->cycle_time);
-	gcl_data->cte = cpu_to_le32(admin_basic->cycle_time_extension);
-
-	for (i = 0; i < gcl_len; i++) {
-		struct gce *temp_gce = gce + i;
-		struct tsn_qbv_entry *temp_entry;
-
-		temp_entry = admin_basic->control_list + i;
-
-		temp_gce->gate = temp_entry->gate_state;
-		temp_gce->period = cpu_to_le32(temp_entry->time_interval);
-	}
-
-	cbdr->length = cpu_to_le16(data_size);
-	cbdr->status_flags = 0;
-
-	dma = dma_map_single(&priv->si->pdev->dev, gcl_data,
-			     data_size, DMA_TO_DEVICE);
-	if (dma_mapping_error(&priv->si->pdev->dev, dma)) {
-		netdev_err(priv->si->ndev, "DMA mapping failed!\n");
-		kfree(gcl_data);
-		return -ENOMEM;
-	}
-
-	cbdr->addr[0] = lower_32_bits(dma);
-	cbdr->addr[1] = upper_32_bits(dma);
-	cbdr->cmd = 0;
-	cbdr->cls = BDCR_CMD_PORT_GCL;
-
-	/* Updated by ENETC on completion of the configuration
-	 * command. A zero value indicates success.
-	 */
-	cbdr->status_flags = 0;
-
-	xmit_cbdr(priv->si, curr_cbd);
-
-	memcpy(&port->nd.ntdata, admin_conf, sizeof(*admin_conf));
-
-	tempclock = ((u64)le32_to_cpu(gcl_config->ccth)) << 32;
-	port->nd.ntdata.qbv_notify.admin.base_time =
-		le32_to_cpu(gcl_config->cctl) + tempclock;
-
-	memset(cbdr, 0, sizeof(struct enetc_cbd));
-	dma_unmap_single(&priv->si->pdev->dev, dma, data_size, DMA_TO_DEVICE);
-	kfree(gcl_data);
-
-	call_tsn_notifiers(TSN_QBV_CONFIGCHANGETIME_ARRIVE,
-			   ndev, &port->nd);
-
-	return 0;
-}
-
-/* CBD Class 5: Time Gated Scheduling Gate Control List query
- * Descriptor - Long Format
- */
-int enetc_qbv_get(struct net_device *ndev, struct tsn_qbv_conf *admin_conf)
-{
-	struct enetc_cbd *cbdr;
-	struct tgs_gcl_resp *gcl_data;
-	struct tgs_gcl_query *gcl_query;
-	struct gce *gce;
-	struct tsn_qbv_basic *admin_basic = &admin_conf->admin;
-	struct enetc_ndev_priv *priv = netdev_priv(ndev);
-	dma_addr_t dma;
-	int curr_cbd;
-	u16 maxlen;
-	u16 data_size, dma_size;
-	u16 admin_len;
-	u16 oper_len;
-	u64 temp;
-	int i;
-
-	if (enetc_rd(&priv->si->hw, ENETC_QBV_PTGCR_OFFSET) & ENETC_QBV_TGE) {
-		admin_conf->gate_enabled = true;
-	} else {
-		admin_conf->gate_enabled = false;
-		return 0;
-	}
-
-	curr_cbd = alloc_cbdr(priv->si, &cbdr);
-
-	gcl_query =  &cbdr->gcl_query;
-
-	maxlen = enetc_get_max_gcl_len(&priv->si->hw);
-
-	data_size = sizeof(struct tgs_gcl_resp)
-			+ sizeof(struct gce) * 2 * maxlen;
-
-	gcl_data = kzalloc(data_size, __GFP_DMA | GFP_KERNEL);
-	if (!gcl_data)
-		return -ENOMEM;
-
-	gce = (struct gce *)(gcl_data + 1);
-
-	gcl_query->acl_len = cpu_to_le16(maxlen);
-
-	dma_size = cpu_to_le16(data_size);
-	cbdr->length = dma_size;
-	cbdr->status_flags = 0;
-
-	dma = dma_map_single(&priv->si->pdev->dev, gcl_data,
-			     data_size, DMA_FROM_DEVICE);
-	if (dma_mapping_error(&priv->si->pdev->dev, dma)) {
-		netdev_err(priv->si->ndev, "DMA mapping failed!\n");
-		kfree(gcl_data);
-		return -ENOMEM;
-	}
-
-	cbdr->addr[0] = lower_32_bits(dma);
-	cbdr->addr[1] = upper_32_bits(dma);
-	cbdr->cmd = 1;
-	cbdr->cls = BDCR_CMD_PORT_GCL;
-	xmit_cbdr(priv->si, curr_cbd);
-	dma_unmap_single(&priv->si->pdev->dev, dma, data_size, DMA_FROM_DEVICE);
-
-	/* since cbdr already passed to free, below could be get wrong */
-	admin_len = le16_to_cpu(gcl_query->admin_list_len);
-	oper_len = le16_to_cpu(gcl_query->oper_list_len);
-
-	admin_basic->control_list_length = admin_len;
-
-	temp = ((u64)le32_to_cpu(gcl_data->abth)) << 32;
-	admin_basic->base_time = le32_to_cpu(gcl_data->abtl) + temp;
-
-	admin_basic->cycle_time = le32_to_cpu(gcl_data->act);
-	admin_basic->cycle_time_extension = le32_to_cpu(gcl_data->acte);
-
-	admin_basic->control_list = kcalloc(admin_len,
-					    sizeof(*admin_basic->control_list),
-					    GFP_KERNEL);
-	if (!admin_basic->control_list) {
-		memset(cbdr, 0, sizeof(*cbdr));
-		kfree(gcl_data);
-		return -ENOMEM;
-	}
-
-	for (i = 0; i < admin_len; i++) {
-		struct gce *temp_gce = gce + i;
-		struct tsn_qbv_entry *temp_entry;
-
-		temp_entry = admin_basic->control_list + i;
-
-		temp_entry->gate_state = temp_gce->gate;
-		temp_entry->time_interval = le32_to_cpu(temp_gce->period);
-	}
-
-	/* Updated by ENETC on completion of the configuration
-	 * command. A zero value indicates success.
-	 */
-	admin_conf->config_change = true;
-
-	memset(cbdr, 0, sizeof(*cbdr));
-	kfree(gcl_data);
-
-	return 0;
-}
-
-int enetc_qbv_get_status(struct net_device *ndev,
-			 struct tsn_qbv_status *status)
-{
-	struct enetc_cbd *cbdr;
-	struct tgs_gcl_resp *gcl_data;
-	struct tgs_gcl_query *gcl_query;
-	struct gce *gce;
-	struct tsn_qbv_basic *oper_basic;
-	struct enetc_ndev_priv *priv;
-	dma_addr_t dma;
-	int curr_cbd;
-	u16 maxlen;
-	u16 data_size, dma_size;
-	u16 admin_len;
-	u16 oper_len;
-	u64 temp;
-	int i;
-
-	if (!ndev)
-		return -EINVAL;
-
-	if (!status)
-		return -EINVAL;
-
-	oper_basic = &status->oper;
-	priv = netdev_priv(ndev);
-
-	if (!(enetc_rd(&priv->si->hw, ENETC_QBV_PTGCR_OFFSET) & ENETC_QBV_TGE))
-		return -EINVAL;
-
-	curr_cbd = alloc_cbdr(priv->si, &cbdr);
-
-	gcl_query = &cbdr->gcl_query;
-
-	maxlen = enetc_get_max_gcl_len(&priv->si->hw);
-
-	data_size = sizeof(struct tgs_gcl_resp) +
-			sizeof(struct gce) * 2 * maxlen;
-
-	gcl_data = kzalloc(data_size, __GFP_DMA | GFP_KERNEL);
-	if (!gcl_data)
-		return -ENOMEM;
-
-	gce = (struct gce *)(gcl_data + 1);
-
-	gcl_query->acl_len = cpu_to_le16(maxlen);
-	gcl_query->ocl_len = cpu_to_le16(maxlen);
-
-	dma_size = cpu_to_le16(data_size);
-	cbdr->length = dma_size;
-	cbdr->status_flags = 0; /* long format command no ie */
-
-	dma = dma_map_single(&priv->si->pdev->dev, gcl_data,
-			     data_size, DMA_FROM_DEVICE);
-	if (dma_mapping_error(&priv->si->pdev->dev, dma)) {
-		netdev_err(priv->si->ndev, "DMA mapping failed!\n");
-		kfree(gcl_data);
-		return -ENOMEM;
-	}
-
-	cbdr->addr[0] = lower_32_bits(dma);
-	cbdr->addr[1] = upper_32_bits(dma);
-	cbdr->cmd = 1;
-	cbdr->cls = BDCR_CMD_PORT_GCL;
-	xmit_cbdr(priv->si, curr_cbd);
-	dma_unmap_single(&priv->si->pdev->dev, dma, data_size, DMA_FROM_DEVICE);
-
-	/* since cbdr already passed to free, below could be get wrong */
-	admin_len = le16_to_cpu(gcl_query->admin_list_len);
-	oper_len = le16_to_cpu(gcl_query->oper_list_len);
-
-	if (enetc_rd(&priv->si->hw, ENETC_QBV_PTGAGLSR_OFFSET) &
-						ENETC_QBV_CFG_PEND_MASK) {
-		status->config_pending = true;
-		goto exit;
-	}
-
-	/* The Oper and Admin timing fields exist in the response buffer even
-	 * if no valid corresponding lists exists. These fields are considered
-	 * invalid if the corresponding list does not exist.
-	 */
-	status->config_pending = false;
-	temp = ((u64)le32_to_cpu(gcl_data->ccth)) << 32;
-	status->config_change_time = le32_to_cpu(gcl_data->cctl) + temp;
-
-	temp = ((u64)le32_to_cpu(gcl_data->cceh)) << 32;
-	status->config_change_error = le32_to_cpu(gcl_data->ccel) + temp;
-
-	/* changed to SITGTGR */
-	status->tick_granularity = enetc_rd(&priv->si->hw, ENETC_SITGTGR);
-
-	/* current time */
-	status->current_time = get_current_time(priv->si);
-
-	status->supported_list_max = maxlen;
-
-	/* status->oper.gate_states , no init oper/admin gate state */
-	status->oper.control_list_length = oper_len;
-	temp = ((u64)le32_to_cpu(gcl_data->obth)) << 32;
-	status->oper.base_time = le32_to_cpu(gcl_data->obtl) + temp;
-	status->oper.cycle_time = le32_to_cpu(gcl_data->oct);
-	status->oper.cycle_time_extension = le32_to_cpu(gcl_data->octe);
-
-	oper_basic->control_list =
-		kcalloc(oper_len, sizeof(*oper_basic->control_list), GFP_KERNEL);
-	if (!oper_basic->control_list) {
-		memset(cbdr, 0, sizeof(*cbdr));
-		kfree(gcl_data);
-		return -ENOMEM;
-	}
-
-	for (i = 0; i < oper_len; i++) {
-		struct gce *temp_gce = gce + maxlen + i;
-		struct tsn_qbv_entry *temp_entry = oper_basic->control_list + i;
-
-		temp_entry->gate_state = temp_gce->gate;
-		temp_entry->time_interval = le32_to_cpu(temp_gce->period);
-	}
-
-exit:
-	memset(cbdr, 0, sizeof(*cbdr));
-	kfree(gcl_data);
-	return 0;
-}
-
-/* CBD Class 7: Stream Identity Entry Set Descriptor - Long Format */
-int enetc_cb_streamid_set(struct net_device *ndev, u32 index,
-			  bool en, struct tsn_cb_streamid *streamid)
-{
-	struct enetc_cbd *cbdr;
-	void *si_data;
-	struct null_streamid_data *si_data1;
-	struct smac_streamid_data *si_data2;
-	struct streamid_conf *si_conf;
-	struct enetc_ndev_priv *priv;
-	dma_addr_t dma;
-	u16 data_size, dma_size;
-	int curr_cbd;
-
-	if (!ndev)
-		return -EINVAL;
-
-	priv = netdev_priv(ndev);
-
-	curr_cbd = alloc_cbdr(priv->si, &cbdr);
-
-	cbdr->index = cpu_to_le16((u16)index);
-	cbdr->cmd = 0;
-	cbdr->cls = BDCR_CMD_STREAM_IDENTIFY;
-	cbdr->status_flags = 0;
-
-	data_size = sizeof(struct null_streamid_data);
-	si_data = kzalloc(data_size, __GFP_DMA | GFP_KERNEL);
-	cbdr->length = cpu_to_le16(data_size);
-
-	dma = dma_map_single(&priv->si->pdev->dev, si_data,
-			     data_size, DMA_FROM_DEVICE);
-	if (dma_mapping_error(&priv->si->pdev->dev, dma)) {
-		netdev_err(priv->si->ndev, "DMA mapping failed!\n");
-		kfree(si_data);
-		return -ENOMEM;
-	}
-
-	cbdr->addr[0] = lower_32_bits(dma);
-	cbdr->addr[1] = upper_32_bits(dma);
-	si_data1 = (struct null_streamid_data *)si_data;
-	si_data1->dmac[0] = 0xFF;
-	si_data1->dmac[1] = 0xFF;
-	si_data1->dmac[2] = 0xFF;
-	si_data1->dmac[3] = 0xFF;
-	si_data1->dmac[4] = 0xFF;
-	si_data1->dmac[5] = 0xFF;
-	si_data1->vid_vidm_tg =
-		cpu_to_le16(ENETC_CBDR_SID_VID_MASK
-			    + ((0x3 << 14) | ENETC_CBDR_SID_VIDM));
-
-	si_conf = &cbdr->sid_set;
-	/* Only one port supported for one entry, set itself */
-	si_conf->iports = 1 << (priv->si->pdev->devfn & 0x7);
-	si_conf->id_type = 1;
-	si_conf->oui[2] = 0x0;
-	si_conf->oui[1] = 0x80;
-	si_conf->oui[0] = 0xC2;
-
-	xmit_cbdr(priv->si, curr_cbd);
-
-	memset(cbdr, 0, sizeof(*cbdr));
-	kfree(si_data);
-
-	if (!en)
-		return 0;
-
-	curr_cbd = alloc_cbdr(priv->si, &cbdr);
-
-	cbdr->index = cpu_to_le16((u16)index);
-	cbdr->cmd = 0;
-	cbdr->cls = BDCR_CMD_STREAM_IDENTIFY;
-	cbdr->status_flags = 0;
-
-	si_conf = &cbdr->sid_set;
-	si_conf->en = 0x80;
-	si_conf->stream_handle = cpu_to_le32(streamid->handle);
-	si_conf->iports = 1 << (priv->si->pdev->devfn & 0x7);
-	si_conf->id_type = streamid->type;
-	si_conf->oui[2] = 0x0;
-	si_conf->oui[1] = 0x80;
-	si_conf->oui[0] = 0xC2;
-
-	if (si_conf->id_type == 1) {
-		data_size = sizeof(struct null_streamid_data);
-		si_data = kzalloc(data_size, __GFP_DMA | GFP_KERNEL);
-	} else if (si_conf->id_type == 2) {
-		data_size = sizeof(struct smac_streamid_data);
-		si_data = kzalloc(data_size, __GFP_DMA | GFP_KERNEL);
-	} else {
-		return -EINVAL;
-	}
-
-	if (!si_data)
-		return -ENOMEM;
-
-	dma_size = cpu_to_le16(data_size);
-	cbdr->length = dma_size;
-	cbdr->status_flags = 0;
-
-	dma = dma_map_single(&priv->si->pdev->dev, si_data,
-			     data_size, DMA_FROM_DEVICE);
-	if (dma_mapping_error(&priv->si->pdev->dev, dma)) {
-		netdev_err(priv->si->ndev, "DMA mapping failed!\n");
-		memset(cbdr, 0, sizeof(*cbdr));
-		kfree(si_data);
-		return -ENOMEM;
-	}
-	cbdr->addr[0] = lower_32_bits(dma);
-	cbdr->addr[1] = upper_32_bits(dma);
-
-	/* VIDM default to be 1.
-	 * VID Match. If set (b1) then the VID must match, otherwise
-	 * any VID is considered a match. VIDM setting is only used
-	 * when TG is set to b01.
-	 */
-	if (si_conf->id_type == 1) {
-		si_data1 = (struct null_streamid_data *)si_data;
-		si_data1->dmac[0] = streamid->para.nid.dmac & 0xFF;
-		si_data1->dmac[1] = (streamid->para.nid.dmac >> 8) & 0xFF;
-		si_data1->dmac[2] = (streamid->para.nid.dmac >> 16) & 0xFF;
-		si_data1->dmac[3] = (streamid->para.nid.dmac >> 24) & 0xFF;
-		si_data1->dmac[4] = (streamid->para.nid.dmac >> 32) & 0xFF;
-		si_data1->dmac[5] = (streamid->para.nid.dmac >> 40) & 0xFF;
-		si_data1->vid_vidm_tg =
-		cpu_to_le16((streamid->para.nid.vid & ENETC_CBDR_SID_VID_MASK) +
-			    ((((u16)(streamid->para.nid.tagged) & 0x3) << 14)
-			     | ENETC_CBDR_SID_VIDM));
-	} else if (si_conf->id_type == 2) {
-		si_data2 = (struct smac_streamid_data *)si_data;
-		si_data2->smac[0] = streamid->para.sid.smac & 0xFF;
-		si_data2->smac[1] = (streamid->para.sid.smac >> 8) & 0xFF;
-		si_data2->smac[2] = (streamid->para.sid.smac >> 16) & 0xFF;
-		si_data2->smac[3] = (streamid->para.sid.smac >> 24) & 0xFF;
-		si_data2->smac[4] = (streamid->para.sid.smac >> 32) & 0xFF;
-		si_data2->smac[5] = (streamid->para.sid.smac >> 40) & 0xFF;
-		si_data2->vid_vidm_tg =
-		cpu_to_le16((streamid->para.sid.vid & ENETC_CBDR_SID_VID_MASK) +
-			    ((((u16)(streamid->para.sid.tagged) & 0x3) << 14)
-			     | ENETC_CBDR_SID_VIDM));
-	}
-
-	xmit_cbdr(priv->si, curr_cbd);
-
-	memset(cbdr, 0, sizeof(*cbdr));
-	kfree(si_data);
-
-	return 0;
-}
-
-/* CBD Class 7: Stream Identity Entry Query Descriptor - Long Format */
-int enetc_cb_streamid_get(struct net_device *ndev, u32 index,
-			  struct tsn_cb_streamid *streamid)
-{
-	struct enetc_cbd *cbdr;
-	struct streamid_query_resp *si_data;
-	struct enetc_ndev_priv *priv;
-	dma_addr_t dma;
-	u16 data_size, dma_size;
-	int curr_cbd;
-	int valid;
-
-	if (!ndev)
-		return -EINVAL;
-
-	priv = netdev_priv(ndev);
-
-	curr_cbd = alloc_cbdr(priv->si, &cbdr);
-
-	cbdr->index = cpu_to_le32(index);
-	cbdr->cmd = 1;
-	cbdr->cls = BDCR_CMD_STREAM_IDENTIFY;
-	cbdr->status_flags = 0;
-
-	data_size = sizeof(struct streamid_query_resp);
-	si_data = kzalloc(data_size, __GFP_DMA | GFP_KERNEL);
-	if (!si_data)
-		return -ENOMEM;
-
-	dma_size = cpu_to_le16(data_size);
-	cbdr->length = dma_size;
-	cbdr->status_flags = 0; /* long format command no ie */
-
-	dma = dma_map_single(&priv->si->pdev->dev, si_data,
-			     data_size, DMA_FROM_DEVICE);
-	if (dma_mapping_error(&priv->si->pdev->dev, dma)) {
-		netdev_err(priv->si->ndev, "DMA mapping failed!\n");
-		kfree(si_data);
-		return -ENOMEM;
-	}
-	cbdr->addr[0] = lower_32_bits(dma);
-	cbdr->addr[1] = upper_32_bits(dma);
-
-	xmit_cbdr(priv->si, curr_cbd);
-
-	streamid->type = si_data->id_type;
-
-	if (streamid->type == 1) {
-		streamid->para.nid.dmac = si_data->mac[0]
-			+ ((u64)si_data->mac[1] << 8)
-			+ ((u64)si_data->mac[2] << 16)
-			+ ((u64)si_data->mac[3] << 24)
-			+ ((u64)si_data->mac[4] << 32)
-			+ ((u64)si_data->mac[5] << 40);
-		/* VID Match. If set (b1) then the VID must match, otherwise
-		 * any VID is considered a match.
-		 */
-		streamid->para.nid.vid =
-				le16_to_cpu(si_data->vid_vidm_tg
-					    & ENETC_CBDR_SID_VID_MASK);
-		streamid->para.nid.tagged =
-				le16_to_cpu(si_data->vid_vidm_tg >> 14 & 0x3);
-	} else if (streamid->type == 2) {
-		streamid->para.sid.smac = si_data->mac[0]
-			+ ((u64)si_data->mac[1] << 8)
-			+ ((u64)si_data->mac[2] << 16)
-			+ ((u64)si_data->mac[3] << 24)
-			+ ((u64)si_data->mac[4] << 32)
-			+ ((u64)si_data->mac[5] << 40);
-		/* VID Match. If set (b1) then the VID must match, otherwise
-		 * any VID is considered a match.
-		 */
-		streamid->para.sid.vid =
-				le16_to_cpu(si_data->vid_vidm_tg
-					    & ENETC_CBDR_SID_VID_MASK);
-		streamid->para.sid.tagged =
-				le16_to_cpu(si_data->vid_vidm_tg >> 14 & 0x3);
-	}
-
-	streamid->handle = le32_to_cpu(si_data->stream_handle);
-	streamid->ifac_iport = le32_to_cpu(si_data->input_ports);
-	valid = si_data->en ? 1 : 0;
-
-	memset(cbdr, 0, sizeof(*cbdr));
-	kfree(si_data);
-
-	return valid;
-}
-
-/*  CBD Class 7: Stream Identity Statistics Query Descriptor - Long Format */
-int enetc_cb_streamid_counters_get(struct net_device *ndev, u32 index,
-				   struct tsn_cb_streamid_counters *counters)
-{
-	return 0;
-}
-
-void enetc_qci_enable(struct enetc_hw *hw)
-{
-	enetc_wr(hw, ENETC_PPSFPMR, enetc_rd(hw, ENETC_PPSFPMR)
-		 | ENETC_PPSFPMR_PSFPEN | ENETC_PPSFPMR_VS
-		 | ENETC_PPSFPMR_PVC | ENETC_PPSFPMR_PVZC);
-}
-
-void enetc_qci_disable(struct enetc_hw *hw)
-{
-	enetc_wr(hw, ENETC_PPSFPMR, enetc_rd(hw, ENETC_PPSFPMR)
-		 & ~ENETC_PPSFPMR_PSFPEN & ~ENETC_PPSFPMR_VS
-		 & ~ENETC_PPSFPMR_PVC & ~ENETC_PPSFPMR_PVZC);
-}
-
-/* CBD Class 8: Stream Filter Instance Set Descriptor - Short Format */
-int enetc_qci_sfi_set(struct net_device *ndev, u32 index, bool en,
-		      struct tsn_qci_psfp_sfi_conf *tsn_qci_sfi)
-{
-	struct enetc_cbd *cbdr;
-	struct sfi_conf *sfi_config;
-
-	struct enetc_ndev_priv *priv = netdev_priv(ndev);
-	int curr_cbd;
-
-	curr_cbd = alloc_cbdr(priv->si, &cbdr);
-
-	cbdr->index = cpu_to_le16(index);
-	cbdr->cmd = 0;
-	cbdr->cls = BDCR_CMD_STREAM_FILTER;
-	cbdr->status_flags = 0x80;
-	cbdr->length = cpu_to_le16(1);
-
-	sfi_config = &cbdr->sfi_conf;
-	if (en)
-		sfi_config->en = 0x80;
-
-	if (tsn_qci_sfi->stream_handle_spec >= 0) {
-		sfi_config->stream_handle =
-			cpu_to_le32(tsn_qci_sfi->stream_handle_spec);
-		sfi_config->sthm |= 0x80;
-	}
-
-	sfi_config->sg_inst_table_index =
-		cpu_to_le16(tsn_qci_sfi->stream_gate_instance_id);
-	sfi_config->input_ports = 1 << (priv->si->pdev->devfn & 0x7);
-
-	/* The priority value which may be matched against the
-	 * frame’s priority value to determine a match for this entry.
-	 */
-	if (tsn_qci_sfi->priority_spec >= 0)
-		sfi_config->multi |= (tsn_qci_sfi->priority_spec & 0x7) | 0x8;
-
-	/* Filter Type. Identifies the contents of the MSDU/FM_INST_INDEX
-	 * field as being either an MSDU value or an index into the Flow
-	 * Meter Instance table.
-	 */
-	if (tsn_qci_sfi->stream_filter.maximum_sdu_size != 0) {
-		sfi_config->msdu =
-		cpu_to_le16(tsn_qci_sfi->stream_filter.maximum_sdu_size);
-		sfi_config->multi |= 0x40;
-	}
-
-	if (tsn_qci_sfi->stream_filter.flow_meter_instance_id >= 0) {
-		sfi_config->fm_inst_table_index =
-		cpu_to_le16(tsn_qci_sfi->stream_filter.flow_meter_instance_id);
-		sfi_config->multi |= 0x80;
-	}
-
-	/* Stream blocked due to oversized frame enable. TRUE or FALSE */
-	if (tsn_qci_sfi->block_oversize_enable)
-		sfi_config->multi |= 0x20;
-
-	/* Stream blocked due to oversized frame. TRUE or FALSE */
-	if (tsn_qci_sfi->block_oversize)
-		sfi_config->multi |= 0x10;
-
-	xmit_cbdr(priv->si, curr_cbd);
-
-	memset(cbdr, 0, sizeof(*cbdr));
-	return 0;
-}
-
-/* CBD Class 8: Stream Filter Instance Query Descriptor - Short Format */
-int enetc_qci_sfi_get(struct net_device *ndev, u32 index,
-		      struct tsn_qci_psfp_sfi_conf *tsn_qci_sfi)
-{
-	struct enetc_cbd *cbdr;
-	struct sfi_conf *sfi_config;
-	struct enetc_ndev_priv *priv = netdev_priv(ndev);
-	int curr_cbd;
-
-	curr_cbd = alloc_cbdr(priv->si, &cbdr);
-
-	cbdr->index = cpu_to_le16(index);
-	cbdr->cmd = 1;
-	cbdr->cls = BDCR_CMD_STREAM_FILTER;
-	cbdr->status_flags = 0x80;
-
-	xmit_cbdr(priv->si, curr_cbd);
-
-	sfi_config = &cbdr->sfi_conf;
-	if (sfi_config->sthm & 0x80)
-		tsn_qci_sfi->stream_handle_spec =
-			le32_to_cpu(sfi_config->stream_handle);
-	else
-		tsn_qci_sfi->stream_handle_spec = -1;
-
-	tsn_qci_sfi->stream_gate_instance_id =
-		le16_to_cpu(sfi_config->sg_inst_table_index);
-
-	if (sfi_config->multi & 0x8)
-		tsn_qci_sfi->priority_spec =
-			le16_to_cpu(sfi_config->multi & 0x7);
-	else
-		tsn_qci_sfi->priority_spec = -1;
-
-	/* Filter Type. Identifies the contents of the MSDU/FM_INST_INDEX
-	 * field as being either an MSDU value or an index into the Flow
-	 * Meter Instance table.
-	 */
-	if (sfi_config->multi & 0x80)
-		tsn_qci_sfi->stream_filter.flow_meter_instance_id =
-			le16_to_cpu(sfi_config->fm_inst_table_index);
-	else
-		tsn_qci_sfi->stream_filter.flow_meter_instance_id = -1;
-
-	if (sfi_config->multi & 0x40)
-		tsn_qci_sfi->stream_filter.maximum_sdu_size =
-			le16_to_cpu(sfi_config->msdu);
-
-	/* Stream blocked due to oversized frame enable. TRUE or FALSE */
-	if (sfi_config->multi & 0x20)
-		tsn_qci_sfi->block_oversize_enable = true;
-	/* Stream blocked due to oversized frame. TRUE or FALSE */
-	if (sfi_config->multi & 0x10)
-		tsn_qci_sfi->block_oversize = true;
-
-	if (sfi_config->en & 0x80) {
-		memset(cbdr, 0, sizeof(*cbdr));
-		return 1;
-	}
-
-	memset(cbdr, 0, sizeof(*cbdr));
-	return 0;
-}
-
-/* CBD Class 8: Stream Filter Instance Query Statistics
- * Descriptor - Long Format
- */
-int enetc_qci_sfi_counters_get(struct net_device *ndev, u32 index,
-			       struct tsn_qci_psfp_sfi_counters *counters)
-{
-	struct enetc_cbd *cbdr;
-	struct enetc_ndev_priv *priv = netdev_priv(ndev);
-	int curr_cbd;
-	struct sfi_counter_data *sfi_counter_data;
-	dma_addr_t dma;
-	u16 data_size, dma_size;
-
-	curr_cbd = alloc_cbdr(priv->si, &cbdr);
-
-	cbdr->index = cpu_to_le16((u16)index);
-	cbdr->cmd = 2;
-	cbdr->cls = BDCR_CMD_STREAM_FILTER;
-	cbdr->status_flags = 0;
-
-	data_size = sizeof(struct sfi_counter_data);
-	sfi_counter_data = kzalloc(data_size, __GFP_DMA | GFP_KERNEL);
-	if (!sfi_counter_data)
-		return -ENOMEM;
-
-	dma = dma_map_single(&priv->si->pdev->dev, sfi_counter_data,
-			     data_size, DMA_FROM_DEVICE);
-	if (dma_mapping_error(&priv->si->pdev->dev, dma)) {
-		netdev_err(priv->si->ndev, "DMA mapping failed!\n");
-		kfree(sfi_counter_data);
-		return -ENOMEM;
-	}
-	cbdr->addr[0] = lower_32_bits(dma);
-	cbdr->addr[1] = upper_32_bits(dma);
-
-	dma_size = cpu_to_le16(data_size);
-	cbdr->length = dma_size;
-
-	xmit_cbdr(priv->si, curr_cbd);
-
-	counters->matching_frames_count =
-			((u64)le32_to_cpu(sfi_counter_data->matchh) << 32)
-			+ sfi_counter_data->matchl;
-
-	counters->not_passing_sdu_count =
-			((u64)le32_to_cpu(sfi_counter_data->msdu_droph) << 32)
-			+ sfi_counter_data->msdu_dropl;
-
-	counters->passing_sdu_count = counters->matching_frames_count
-				- counters->not_passing_sdu_count;
-
-	counters->not_passing_frames_count =
-		((u64)le32_to_cpu(sfi_counter_data->stream_gate_droph) << 32)
-		+ le32_to_cpu(sfi_counter_data->stream_gate_dropl);
-
-	counters->passing_frames_count = counters->matching_frames_count
-				- counters->not_passing_sdu_count
-				- counters->not_passing_frames_count;
-
-	counters->red_frames_count =
-		((u64)le32_to_cpu(sfi_counter_data->flow_meter_droph) << 32)
-		+ le32_to_cpu(sfi_counter_data->flow_meter_dropl);
-
-	memset(cbdr, 0, sizeof(*cbdr));
-	return 0;
-}
-
-/* CBD Class 9: Stream Gate Instance Table Entry Set
- * Descriptor - Short Format
- */
-int enetc_qci_sgi_set(struct net_device *ndev, u32 index,
-		      struct tsn_qci_psfp_sgi_conf *tsn_qci_sgi)
-{
-	struct enetc_cbd *cbdr, *cbdr_sgcl;
-	struct sgi_table *sgi_config;
-	struct sgcl_conf *sgcl_config;
-	struct sgcl_data *sgcl_data;
-	struct sgce *sgce;
-	struct enetc_ndev_priv *priv = netdev_priv(ndev);
-
-	dma_addr_t dma;
-	u16 data_size, dma_size;
-	int curr_cbd, i;
-
-	/* disable first */
-	curr_cbd = alloc_cbdr(priv->si, &cbdr);
-	memset(cbdr, 0, sizeof(*cbdr));
-
-	cbdr->index = cpu_to_le16(index);
-	cbdr->cmd = 0;
-	cbdr->cls = BDCR_CMD_STREAM_GCL;
-	cbdr->status_flags = 0x80;
-
-	xmit_cbdr(priv->si, curr_cbd);
-
-	if (!tsn_qci_sgi->gate_enabled) {
-		memset(cbdr, 0, sizeof(*cbdr));
-		return 0;
-	}
-
-	/* Re-enable */
-	curr_cbd = alloc_cbdr(priv->si, &cbdr);
-	memset(cbdr, 0, sizeof(*cbdr));
-
-	cbdr->index = cpu_to_le16(index);
-	cbdr->cmd = 0;
-	cbdr->cls = BDCR_CMD_STREAM_GCL;
-	cbdr->status_flags = 0x80;
-
-	sgi_config = &cbdr->sgi_table;
-
-	sgi_config->ocgtst = tsn_qci_sgi->admin.control_list_length ?
-			0x80 : (tsn_qci_sgi->admin.gate_states ? 0x80 : 0x0);
-
-	sgi_config->oipv =
-		tsn_qci_sgi->admin.control_list_length ?
-		0x0 : ((tsn_qci_sgi->admin.init_ipv < 0) ?
-		       0x0 : ((tsn_qci_sgi->admin.init_ipv & 0x7) | 0x8));
-
-	sgi_config->en = 0x80;
-
-	if (tsn_qci_sgi->block_invalid_rx_enable)
-		sgi_config->gset |= 0x80;
-	if (tsn_qci_sgi->block_invalid_rx)
-		sgi_config->gset |= 0x40;
-	if (tsn_qci_sgi->block_octets_exceeded)
-		sgi_config->gset |= 0x10;
-	if (tsn_qci_sgi->block_octets_exceeded_enable)
-		sgi_config->gset |= 0x20;
-
-	xmit_cbdr(priv->si, curr_cbd);
-
-	if (tsn_qci_sgi->admin.control_list_length == 0)
-		goto exit;
-
-	curr_cbd = alloc_cbdr(priv->si, &cbdr_sgcl);
-	memset(cbdr, 0, sizeof(*cbdr));
-
-	cbdr_sgcl->index = cpu_to_le16(index);
-	cbdr_sgcl->cmd = 1;
-	cbdr_sgcl->cls = BDCR_CMD_STREAM_GCL;
-	cbdr_sgcl->status_flags = 0;
-
-	sgcl_config = &cbdr_sgcl->sgcl_conf;
-
-	/* tsn_qci_sgi->admin.control_list_length is not zero now */
-	if (tsn_qci_sgi->admin.control_list_length > 4)
-		return -EINVAL;
-
-	sgcl_config->acl_len =
-		(tsn_qci_sgi->admin.control_list_length - 1) & 0x3;
-
-	data_size = struct_size(sgcl_data, sgcl,
-				tsn_qci_sgi->admin.control_list_length);
-
-	sgcl_data = kzalloc(data_size, __GFP_DMA | GFP_KERNEL);
-	if (!sgcl_data)
-		return -ENOMEM;
-
-	dma_size = cpu_to_le16(data_size);
-	cbdr_sgcl->length = dma_size;
-
-	dma = dma_map_single(&priv->si->pdev->dev,
-			     sgcl_data, data_size,
-			     DMA_FROM_DEVICE);
-	if (dma_mapping_error(&priv->si->pdev->dev, dma)) {
-		netdev_err(priv->si->ndev, "DMA mapping failed!\n");
-		memset(cbdr, 0, sizeof(*cbdr));
-		memset(cbdr_sgcl, 0, sizeof(*cbdr_sgcl));
-		kfree(sgcl_data);
-		return -ENOMEM;
-	}
-	cbdr_sgcl->addr[0] = lower_32_bits(dma);
-	cbdr_sgcl->addr[1] = upper_32_bits(dma);
-
-	sgce = (struct sgce *)(sgcl_data + 1);
-
-	if (tsn_qci_sgi->admin.gate_states)
-		sgcl_config->agtst = 0x80;
-
-	sgcl_data->ct = cpu_to_le32(tsn_qci_sgi->admin.cycle_time);
-	sgcl_data->cte = cpu_to_le32(tsn_qci_sgi->admin.cycle_time_extension);
-
-	if (tsn_qci_sgi->admin.init_ipv >= 0)
-		sgcl_config->aipv = (tsn_qci_sgi->admin.init_ipv & 0x7) | 0x8;
-
-	for (i = 0; i < tsn_qci_sgi->admin.control_list_length; i++) {
-		struct tsn_qci_psfp_gcl *temp_sgcl = tsn_qci_sgi->admin.gcl + i;
-		struct sgce *temp_entry = (struct sgce *)(sgce + i);
-
-		if (temp_sgcl->gate_state)
-			temp_entry->multi |= 0x10;
-
-		if (temp_sgcl->ipv >= 0)
-			temp_entry->multi |= ((temp_sgcl->ipv & 0x7) << 5)
-						| 0x08;
-
-		if (temp_sgcl->octet_max)
-			temp_entry->multi |= 0x01;
-
-		temp_entry->interval = cpu_to_le32(temp_sgcl->time_interval);
-		temp_entry->msdu[0] = temp_sgcl->octet_max & 0xFF;
-		temp_entry->msdu[1] = (temp_sgcl->octet_max >> 8) & 0xFF;
-		temp_entry->msdu[2] = (temp_sgcl->octet_max >> 16) & 0xFF;
-	}
-
-	if (!tsn_qci_sgi->admin.base_time) {
-		sgcl_data->btl =
-			cpu_to_le32(enetc_rd(&priv->si->hw, ENETC_SICTR0));
-		sgcl_data->bth =
-			cpu_to_le32(enetc_rd(&priv->si->hw, ENETC_SICTR1));
-	} else {
-		u32 tempu, templ;
-
-		tempu = upper_32_bits(tsn_qci_sgi->admin.base_time);
-		templ = lower_32_bits(tsn_qci_sgi->admin.base_time);
-		sgcl_data->bth = cpu_to_le32(tempu);
-		sgcl_data->btl = cpu_to_le32(templ);
-	}
-
-	xmit_cbdr(priv->si, curr_cbd);
-
-	memset(cbdr_sgcl, 0, sizeof(*cbdr_sgcl));
-	kfree(sgcl_data);
-
-exit:
-	memset(cbdr, 0, sizeof(*cbdr));
-	return 0;
-}
-
-/* CBD Class 9: Stream Gate Instance Table Entry Query
- * Descriptor - Short Format
- */
-int enetc_qci_sgi_get(struct net_device *ndev, u32 index,
-		      struct tsn_qci_psfp_sgi_conf *tsn_qci_sgi)
-{
-	struct enetc_cbd *cbdr, *cbdr_sgcl;
-	struct sgi_table *sgi_config;
-	struct sgcl_query *sgcl_query;
-	struct sgcl_query_resp *sgcl_data;
-	struct sgce *sgce;
-	struct enetc_ndev_priv *priv = netdev_priv(ndev);
-	dma_addr_t dma;
-	u16 data_size, dma_size, gcl_data_stat = 0;
-	u8 admin_len = 0;
-	int curr_cbd, i;
-
-	curr_cbd = alloc_cbdr(priv->si, &cbdr);
-
-	cbdr->index = cpu_to_le16(index);
-	cbdr->cmd = 2;
-	cbdr->cls = BDCR_CMD_STREAM_GCL;
-	cbdr->status_flags = 0x80;
-
-	xmit_cbdr(priv->si, curr_cbd);
-
-	sgi_config = &cbdr->sgi_table;
-
-	tsn_qci_sgi->admin.gate_states = (sgi_config->ocgtst & 0x80) ?
-						true : false;
-	if (sgi_config->oipv & 0x08)
-		tsn_qci_sgi->admin.init_ipv = sgi_config->oipv & 0x7;
-	else
-		tsn_qci_sgi->admin.init_ipv = -1;
-
-	if (sgi_config->en & 0x80)
-		tsn_qci_sgi->gate_enabled = true;
-	if (sgi_config->gset & 0x80)
-		tsn_qci_sgi->block_invalid_rx_enable = true;
-	if (sgi_config->gset & 0x40)
-		tsn_qci_sgi->block_invalid_rx = true;
-	if (sgi_config->gset & 0x20)
-		tsn_qci_sgi->block_octets_exceeded_enable = true;
-	if (sgi_config->gset & 0x10)
-		tsn_qci_sgi->block_octets_exceeded = true;
-
-	/* Check gate list length is zero? */
-	if (!(sgi_config->oacl_len & 0x30)) {
-		tsn_qci_sgi->admin.control_list_length = 0;
-		goto exit;
-	}
-
-	curr_cbd = alloc_cbdr(priv->si, &cbdr_sgcl);
-
-	cbdr_sgcl->index = cpu_to_le16(index);
-	cbdr_sgcl->cmd = 3;
-	cbdr_sgcl->cls = BDCR_CMD_STREAM_GCL;
-	cbdr_sgcl->status_flags = 0;
-
-	data_size = sizeof(struct sgcl_query_resp) + 4 * sizeof(struct sgce);
-
-	sgcl_data = kzalloc(data_size, __GFP_DMA | GFP_KERNEL);
-	if (!sgcl_data)
-		return -ENOMEM;
-
-	dma_size = cpu_to_le16(data_size);
-	cbdr_sgcl->length = dma_size;
-	cbdr_sgcl->status_flags = 0;
-
-	sgcl_query = &cbdr_sgcl->sgcl_query;
-
-	sgcl_query->oacl_len = 0x10;
-
-	dma = dma_map_single(&priv->si->pdev->dev, sgcl_data,
-			     data_size, DMA_FROM_DEVICE);
-	if (dma_mapping_error(&priv->si->pdev->dev, dma)) {
-		netdev_err(priv->si->ndev, "DMA mapping failed!\n");
-		memset(cbdr, 0, sizeof(*cbdr));
-		memset(cbdr_sgcl, 0, sizeof(*cbdr_sgcl));
-		kfree(sgcl_data);
-		return -ENOMEM;
-	}
-	cbdr_sgcl->addr[0] = lower_32_bits(dma);
-	cbdr_sgcl->addr[1] = upper_32_bits(dma);
-
-	xmit_cbdr(priv->si, curr_cbd);
-
-	sgce = (struct sgce *)(sgcl_data + 1);
-
-	gcl_data_stat = le16_to_cpu(sgcl_data->stat);
-	if (gcl_data_stat & 0x10)
-		tsn_qci_sgi->admin.gate_states = true;
-
-	if (gcl_data_stat & 0x80)
-		tsn_qci_sgi->admin.init_ipv = gcl_data_stat & 0x7;
-	else
-		tsn_qci_sgi->admin.init_ipv = -1;
-
-	/* admin_len can also get from gcl_data_stat bit 5,6
-	 * OR sgi_config->oacl_len
-	 */
-	admin_len = (sgcl_query->oacl_len & 0x3) + 1;
-	tsn_qci_sgi->admin.control_list_length = admin_len;
-	tsn_qci_sgi->admin.cycle_time = le32_to_cpu(sgcl_data->act);
-	tsn_qci_sgi->admin.cycle_time_extension = le32_to_cpu(sgcl_data->acte);
-	tsn_qci_sgi->admin.base_time = ((u64)(le32_to_cpu(sgcl_data->abth))
-					      << 32)
-					+ le32_to_cpu(sgcl_data->abtl);
-
-	tsn_qci_sgi->admin.gcl = kcalloc(admin_len,
-					 sizeof(struct tsn_qci_psfp_gcl),
-					 GFP_KERNEL);
-	if (!tsn_qci_sgi->admin.gcl) {
-		kfree(sgcl_data);
-		return -ENOMEM;
-	}
-
-	for (i = 0; i < admin_len; i++) {
-		struct tsn_qci_psfp_gcl *temp_sgcl = tsn_qci_sgi->admin.gcl + i;
-		struct sgce *temp_entry = (struct sgce *)(sgce + i);
-
-		if (temp_entry->multi & 0x10)
-			temp_sgcl->gate_state = true;
-
-		if (temp_entry->multi & 0x08)
-			temp_sgcl->ipv = temp_entry->multi >> 5;
-		else
-			temp_sgcl->ipv = -1;
-
-		temp_sgcl->time_interval = le32_to_cpu(temp_entry->interval);
-
-		if (temp_entry->multi & 0x01)
-			temp_sgcl->octet_max = (temp_entry->msdu[0] & 0xff)
-				| (((u32)temp_entry->msdu[1] << 8) & 0xff00)
-				| (((u32)temp_entry->msdu[1] << 16) & 0xff0000);
-		else
-			temp_sgcl->octet_max = 0;
-	}
-
-	memset(cbdr_sgcl, 0, sizeof(*cbdr_sgcl));
-	kfree(sgcl_data);
-
-exit:
-	memset(cbdr, 0, sizeof(*cbdr));
-	return 0;
-}
-
-/* CBD Class 9: Stream Gate Instance Table Entry Query Descriptor
- * CBD Class 9: Stream Gate Control List Query Descriptor
- */
-int enetc_qci_sgi_status_get(struct net_device *ndev, u16 index,
-			     struct tsn_psfp_sgi_status *status)
-{
-	struct enetc_cbd *cbdr_sgi, *cbdr_sgcl;
-	struct sgi_table *sgi_config;
-	struct sgcl_query *sgcl_query;
-	struct sgcl_query_resp *sgcl_data;
-	struct sgce *sgce;
-	struct enetc_ndev_priv *priv = netdev_priv(ndev);
-	dma_addr_t dma;
-	u16 data_size, dma_size, gcl_data_stat = 0;
-	u8 oper_len = 0;
-	int curr_cbd, i;
-
-	curr_cbd = alloc_cbdr(priv->si, &cbdr_sgi);
-
-	cbdr_sgi->index = cpu_to_le16(index);
-	cbdr_sgi->cmd = 2;
-	cbdr_sgi->cls = BDCR_CMD_STREAM_GCL;
-	cbdr_sgi->status_flags = 0x80;
-
-	sgi_config = &cbdr_sgi->sgi_table;
-
-	if (sgi_config->gset & 0x4)
-		status->config_pending = true;
-
-	status->oper.gate_states = ((sgi_config->ocgtst & 0x80) ? true : false);
-
-	/* Check gate list length is zero */
-	if (!(sgi_config->oacl_len & 0x30)) {
-		status->oper.control_list_length = 0;
-		goto cmd2quit;
-	}
-
-	xmit_cbdr(priv->si, curr_cbd);
-
-	curr_cbd = alloc_cbdr(priv->si, &cbdr_sgcl);
-
-	cbdr_sgcl->index = cpu_to_le16(index);
-	cbdr_sgcl->cmd = 3;
-	cbdr_sgcl->cls = BDCR_CMD_STREAM_GCL;
-	cbdr_sgcl->status_flags = 0;
-
-	/* Max size */
-	data_size = sizeof(struct sgcl_query_resp) + 4 * sizeof(struct sgce);
-
-	sgcl_data = kzalloc(data_size, __GFP_DMA | GFP_KERNEL);
-	if (!sgcl_data)
-		return -ENOMEM;
-
-	dma_size = cpu_to_le16(data_size);
-	cbdr_sgcl->length = dma_size;
-	cbdr_sgcl->status_flags = 0;
-
-	sgcl_query = &cbdr_sgcl->sgcl_query;
-
-	sgcl_query->oacl_len = 0x20;
-
-	dma = dma_map_single(&priv->si->pdev->dev, sgcl_data,
-			     data_size, DMA_FROM_DEVICE);
-	if (dma_mapping_error(&priv->si->pdev->dev, dma)) {
-		netdev_err(priv->si->ndev, "DMA mapping failed!\n");
-		memset(cbdr_sgi, 0, sizeof(*cbdr_sgi));
-		memset(cbdr_sgcl, 0, sizeof(*cbdr_sgcl));
-		kfree(sgcl_data);
-		return -ENOMEM;
-	}
-	cbdr_sgcl->addr[0] = lower_32_bits(dma);
-	cbdr_sgcl->addr[1] = upper_32_bits(dma);
-
-	xmit_cbdr(priv->si, curr_cbd);
-
-	sgce = (struct sgce *)(sgcl_data + 1);
-
-	/* oper_len can also get from gcl_data_stat bit 5,6
-	 * OR sgi_config->oacl_len
-	 */
-	oper_len = ((sgcl_query->oacl_len & 0x0c) >> 2) + 1;
-
-	/* Get Stream Gate Control List */
-	status->oper.cycle_time = le32_to_cpu(sgcl_data->oct);
-	status->oper.cycle_time_extension = le32_to_cpu(sgcl_data->octe);
-	status->oper.base_time = le32_to_cpu(sgcl_data->obtl)
-				+ ((u64)le32_to_cpu(sgcl_data->obth) << 32);
-	status->oper.control_list_length = oper_len;
-
-	gcl_data_stat = le16_to_cpu(sgcl_data->stat);
-	if (gcl_data_stat & 0x400)
-		status->oper.init_ipv = gcl_data_stat & 0x38 >> 7;
-	else
-		status->oper.init_ipv = -1;
-
-	if (gcl_data_stat & 0x800)
-		status->oper.gate_states = true;
-
-	status->oper.gcl = kcalloc(oper_len,
-				   sizeof(struct tsn_qci_psfp_gcl),
-				   GFP_KERNEL);
-	if (!status->oper.gcl) {
-		memset(cbdr_sgi, 0, sizeof(*cbdr_sgi));
-		memset(cbdr_sgcl, 0, sizeof(*cbdr_sgcl));
-		kfree(sgcl_data);
-		return -ENOMEM;
-	}
-
-	for (i = 0; i < oper_len; i++) {
-		struct tsn_qci_psfp_gcl *temp_sgcl = status->oper.gcl + i;
-		struct sgce *temp_entry = (struct sgce *)(sgce + i);
-
-		if (temp_entry->multi & 0x10)
-			temp_sgcl->gate_state = true;
-
-		if (temp_entry->multi & 0x08)
-			temp_sgcl->ipv = temp_entry->multi >> 5;
-		else
-			temp_sgcl->ipv = -1;
-
-		temp_sgcl->time_interval = le32_to_cpu(temp_entry->interval);
-
-		if (temp_entry->multi & 0x01)
-			temp_sgcl->octet_max = temp_entry->msdu[0]
-					| ((((u32)temp_entry->msdu[1]) << 8)
-					   & 0xff00)
-					| ((((u32)temp_entry->msdu[2]) << 16)
-					   & 0xff0000);
-		else
-			temp_sgcl->octet_max = 0;
-	}
-
-	status->config_change_time = le32_to_cpu(sgcl_data->cctl)
-				+ ((u64)le32_to_cpu(sgcl_data->ccth) << 32);
-
-	memset(cbdr_sgcl, 0, sizeof(*cbdr_sgcl));
-	kfree(sgcl_data);
-
-cmd2quit:
-	/* changed to SITGTGR */
-	status->tick_granularity = enetc_rd(&priv->si->hw, ENETC_SITGTGR);
-
-	/* current time */
-	status->current_time = get_current_time(priv->si);
-
-	memset(cbdr_sgi, 0, sizeof(*cbdr_sgi));
-
-	return 0;
-}
-
-/* CBD Class 10: Flow Meter Instance Set Descriptor - Short Format */
-int enetc_qci_fmi_set(struct net_device *ndev, u32 index, bool enable,
-		      struct tsn_qci_psfp_fmi *tsn_qci_fmi)
-{
-	struct enetc_cbd *cbdr;
-	struct fmi_conf *fmi_config;
-
-	struct enetc_ndev_priv *priv = netdev_priv(ndev);
-	int curr_cbd;
-	u64 temp = 0;
-
-	curr_cbd = alloc_cbdr(priv->si, &cbdr);
-
-	cbdr->index = cpu_to_le16((u16)index);
-	cbdr->cmd = 0;
-	cbdr->cls = BDCR_CMD_FLOW_METER;
-	cbdr->status_flags = 0x80;
-
-	xmit_cbdr(priv->si, curr_cbd);
-
-	if (!enable) {
-		memset(cbdr, 0, sizeof(*cbdr));
-		return 0;
-	}
-
-	/* Re-enable */
-	curr_cbd = alloc_cbdr(priv->si, &cbdr);
-	memset(cbdr, 0, sizeof(*cbdr));
-	cbdr->index = cpu_to_le16((u16)index);
-	cbdr->cmd = 0;
-	cbdr->cls = BDCR_CMD_FLOW_METER;
-	cbdr->status_flags = 0x80;
-
-	fmi_config = &cbdr->fmi_conf;
-	fmi_config->en = 0x80;
-	if (tsn_qci_fmi->cir) {
-		temp = (u64)1000000 * tsn_qci_fmi->cir;
-		temp = temp / 3725;
-	}
-	fmi_config->cir = cpu_to_le32((u32)temp);
-	fmi_config->cbs = cpu_to_le32(tsn_qci_fmi->cbs);
-	temp = 0;
-	if (tsn_qci_fmi->eir) {
-		temp = (u64)1000000 * tsn_qci_fmi->eir;
-		temp = temp / 3725;
-	}
-	fmi_config->eir = cpu_to_le32((u32)temp);
-	fmi_config->ebs = cpu_to_le32(tsn_qci_fmi->ebs);
-
-	if (tsn_qci_fmi->mark_red)
-		fmi_config->conf |= 0x1;
-
-	if (tsn_qci_fmi->mark_red_enable)
-		fmi_config->conf |= 0x2;
-
-	if (tsn_qci_fmi->drop_on_yellow)
-		fmi_config->conf |= 0x4;
-
-	if (tsn_qci_fmi->cm)
-		fmi_config->conf |= 0x8;
-
-	if (tsn_qci_fmi->cf)
-		fmi_config->conf |= 0x10;
-
-	xmit_cbdr(priv->si, curr_cbd);
-
-	memset(cbdr, 0, sizeof(*cbdr));
-	return 0;
-}
-
-/* CBD Class 10: Flow Meter Instance Query Descriptor - Short Format */
-int enetc_qci_fmi_get(struct net_device *ndev, u32 index,
-		      struct tsn_qci_psfp_fmi *tsn_qci_fmi,
-		      struct tsn_qci_psfp_fmi_counters *counters)
-{
-	struct enetc_cbd *cbdr;
-	struct fmi_conf *fmi_config;
-	struct enetc_ndev_priv *priv = netdev_priv(ndev);
-	int curr_cbd;
-	u16 data_size, dma_size;
-	dma_addr_t dma;
-	struct fmi_query_stat_resp *fmi_counter_data;
-	u64 temp = 0;
-
-	curr_cbd = alloc_cbdr(priv->si, &cbdr);
-
-	cbdr->index = cpu_to_le16(index);
-	cbdr->cmd = 1;
-	cbdr->cls = BDCR_CMD_FLOW_METER;
-	cbdr->status_flags = 0x80;
-
-	xmit_cbdr(priv->si, curr_cbd);
-
-	fmi_config = &cbdr->fmi_conf;
-	if (fmi_config->cir) {
-		temp = (u64)3725 * fmi_config->cir;
-		temp = temp / 1000;
-	}
-	tsn_qci_fmi->cir = le32_to_cpu((u32)temp);
-	tsn_qci_fmi->cbs = le32_to_cpu(fmi_config->cbs);
-	temp = 0;
-	if (fmi_config->eir) {
-		temp = (u64)3725 * fmi_config->eir;
-		temp = temp / 1000;
-	}
-	tsn_qci_fmi->eir = le32_to_cpu((u32)temp);
-	tsn_qci_fmi->ebs = le32_to_cpu(fmi_config->ebs);
-
-	if (fmi_config->conf & 0x1)
-		tsn_qci_fmi->mark_red = true;
-
-	if (fmi_config->conf & 0x2)
-		tsn_qci_fmi->mark_red_enable = true;
-
-	if (fmi_config->conf & 0x4)
-		tsn_qci_fmi->drop_on_yellow = true;
-
-	if (fmi_config->conf & 0x8)
-		tsn_qci_fmi->cm = true;
-
-	if (fmi_config->conf & 0x10)
-		tsn_qci_fmi->cf = true;
-
-	memset(cbdr, 0, sizeof(*cbdr));
-
-	/* Get counters */
-	curr_cbd = alloc_cbdr(priv->si, &cbdr);
-
-	cbdr->index = cpu_to_le16(index);
-	cbdr->cmd = 2;
-	cbdr->cls = BDCR_CMD_FLOW_METER;
-	cbdr->status_flags = 0x0;
-
-	data_size = sizeof(struct fmi_query_stat_resp);
-	fmi_counter_data = kzalloc(data_size, __GFP_DMA | GFP_KERNEL);
-	if (!fmi_counter_data)
-		return -ENOMEM;
-
-	dma = dma_map_single(&priv->si->pdev->dev, fmi_counter_data,
-			     data_size, DMA_FROM_DEVICE);
-	if (dma_mapping_error(&priv->si->pdev->dev, dma)) {
-		netdev_err(priv->si->ndev, "DMA mapping failed!\n");
-		kfree(fmi_counter_data);
-		return -ENOMEM;
-	}
-	cbdr->addr[0] = lower_32_bits(dma);
-	cbdr->addr[1] = upper_32_bits(dma);
-
-	dma_size = cpu_to_le16(data_size);
-	cbdr->length = dma_size;
-
-	xmit_cbdr(priv->si, curr_cbd);
-
-	memcpy(counters, fmi_counter_data, sizeof(*counters));
-
-	return 0;
-}
-
-int enetc_qbu_set(struct net_device *ndev, u8 ptvector)
-{
-	u32 temp;
-	int i;
-	struct enetc_ndev_priv *priv = netdev_priv(ndev);
-
-	temp = enetc_rd(&priv->si->hw, ENETC_QBV_PTGCR_OFFSET);
-	if (temp & ENETC_QBV_TGE)
-		enetc_wr(&priv->si->hw, ENETC_QBV_PTGCR_OFFSET,
-			 temp & (~ENETC_QBV_TGPE));
-
-	for (i = 0; i < 8; i++) {
-		/* 1 Enabled. Traffic is transmitted on the preemptive MAC. */
-		temp = enetc_port_rd(&priv->si->hw, ENETC_PTCFPR(i));
-
-		if ((ptvector >> i) & 0x1)
-			enetc_port_wr(&priv->si->hw,
-				      ENETC_PTCFPR(i),
-				      temp | ENETC_FPE);
-		else
-			enetc_port_wr(&priv->si->hw,
-				      ENETC_PTCFPR(i),
-				      temp & ~ENETC_FPE);
-	}
-
-	return 0;
-}
-
-int enetc_qbu_get(struct net_device *ndev,
-		  struct tsn_preempt_status *preemptstat)
-{
-	int i;
-	struct enetc_ndev_priv *priv = netdev_priv(ndev);
-
-	if (enetc_port_rd(&priv->si->hw, ENETC_PFPMR) & ENETC_PFPMR_PMACE) {
-		preemptstat->preemption_active = true;
-		if (enetc_rd(&priv->si->hw, ENETC_QBV_PTGCR_OFFSET)
-							& ENETC_QBV_TGE)
-			preemptstat->hold_request = 1;
-		else
-			preemptstat->hold_request = 2;
-	} else {
-		preemptstat->preemption_active = false;
-		return 0;
-	}
-
-	for (i = 0; i < 8; i++)
-		if (enetc_port_rd(&priv->si->hw, ENETC_PTCFPR(i)) & 0x80000000)
-			preemptstat->admin_state |= 1 << i;
-
-	preemptstat->hold_advance =
-		enetc_rd(&priv->si->hw, ENETC_QBV_PTGCR_OFFSET) & 0xFFFF;
-	preemptstat->release_advance =
-		enetc_rd(&priv->si->hw, ENETC_QBV_PTGCR_OFFSET) & 0xFFFF;
-
-	return 0;
-}
-
-u32 __enetc_tsn_get_cap(struct enetc_si *si)
-{
-	u32 reg = 0;
-	u32 cap = 0;
-
-	reg = enetc_port_rd(&si->hw, ENETC_PCAPR0);
-
-	if (reg & ENETC_PCAPR0_PSFP)
-		cap |= TSN_CAP_QCI;
-
-	if (reg & ENETC_PCAPR0_TSN)
-		cap |= TSN_CAP_QBV;
-
-	if (reg & ENETC_PCAPR0_QBU)
-		cap |= TSN_CAP_QBU;
-
-	cap |= TSN_CAP_CBS;
-	cap |= TSN_CAP_TBS;
-
-	return cap;
-}
-
-u32 enetc_tsn_get_capability(struct net_device *ndev)
-{
-	struct enetc_ndev_priv *priv = netdev_priv(ndev);
-
-	return __enetc_tsn_get_cap(priv->si);
-}
-
-static int  __enetc_get_max_cap(struct enetc_si *si,
-				struct tsn_qci_psfp_stream_param *stream_para)
-{
-	u32 reg = 0;
-
-	/* Port stream filter capability */
-	reg = enetc_port_rd(&si->hw, ENETC_PSFCAPR);
-	stream_para->max_sf_instance = reg & ENETC_PSFCAPR_MSK;
-	/* Port stream filter capability */
-	reg = enetc_port_rd(&si->hw, ENETC_PSGCAPR);
-	stream_para->max_sg_instance = (reg & ENETC_PSGCAPR_SGIT_MSK);
-	stream_para->supported_list_max = (reg & ENETC_PSGCAPR_GCL_MSK) >> 16;
-	/* Port flow meter capability */
-	reg = enetc_port_rd(&si->hw, ENETC_PFMCAPR);
-	stream_para->max_fm_instance = reg & ENETC_PFMCAPR_MSK;
-
-	return 0;
-}
-
-int enetc_get_max_capa(struct net_device *ndev,
-		      struct tsn_qci_psfp_stream_param *stream_para)
-{
-	struct enetc_ndev_priv *priv = netdev_priv(ndev);
-
-	return __enetc_get_max_cap(priv->si, stream_para);
-}
-
-static int enetc_set_cbs(struct net_device *ndev, u8 tc, u8 bw)
-{
-	struct enetc_ndev_priv *priv = netdev_priv(ndev);
-	struct enetc_si *si = priv->si;
-	struct enetc_cbs *ecbs = si->ecbs;
-	struct cbs *cbs;
-
-	int bw_sum = 0;
-	u32 port_transmit_rate;
-	u32 port_frame_max_size;
-	u8 tc_nums;
-	int i;
-
-	u32 max_interfrence_size;
-	u32 send_slope;
-	u32 hi_credit;
-
-	if (!ecbs)
-		return -ENOMEM;
-
-	port_transmit_rate = priv->speed;
-	if (port_transmit_rate != ecbs->port_transmit_rate)
-		ecbs->port_transmit_rate = port_transmit_rate;
-	port_frame_max_size = ecbs->port_max_size_frame;
-	tc_nums = ecbs->tc_nums;
-	cbs = ecbs->cbs;
-
-	if (tc >= tc_nums) {
-		dev_err(&ndev->dev, "Make sure the TC less than %d\n", tc_nums);
-		return -EINVAL;
-	}
-
-	if (!bw) {
-		if (cbs[tc].enable) {
-			/* Make sure the other TC that are numerically
-			 * lower than this TC have been disabled.
-			 */
-			for (i = 0; i < tc; i++) {
-				if (cbs[i].enable)
-					break;
-			}
-			if (i < tc) {
-				dev_err(&ndev->dev,
-					"TC%d has been disabled first\n", i);
-				return -EINVAL;
-			}
-			memset(&cbs[tc], 0, sizeof(*cbs));
-			cbs[tc].enable = false;
-			enetc_port_wr(&si->hw, ENETC_PTCCBSR1(tc), 0);
-			enetc_port_wr(&si->hw, ENETC_PTCCBSR0(tc), 0);
-		}
-		return 0;
-	}
-
-	/* Make sure the other TC that are numerically
-	 * higher than this TC have been enabled.
-	 */
-	for (i = tc_nums - 1; i > tc; i--) {
-		if (!cbs[i].enable) {
-			dev_err(&ndev->dev,
-				"TC%d has been enabled first\n", i);
-			return -EINVAL;
-		}
-		bw_sum += cbs[i].bw;
-	}
-
-	if (bw_sum + bw >= 100) {
-		dev_err(&ndev->dev,
-			"The sum of all CBS Bandwidth cann't exceed 100\n");
-		return -EINVAL;
-	}
-
-	cbs[tc].bw = bw;
-	cbs[tc].tc_max_sized_frame = enetc_port_rd(&si->hw, ENETC_PTCMSDUR(tc));
-	cbs[tc].idle_slope = port_transmit_rate / 100 * bw;
-	cbs[tc].send_slope = port_transmit_rate - cbs[tc].idle_slope;
-
-	/* For TC7, the max_interfrence_size is ENETC_MAC_MAXFRM_SIZE.
-	 * For TC6, the max_interfrence_size is calculated as below:
-	 *
-	 *      max_interfrence_size = (M0 + Ma + Ra * M0 / (R0 - Ra))
-	 *
-	 * For other traffic class, for example SR class Q:
-	 *
-	 *                            R0 * (M0 + Ma + ... + Mp)
-	 *      max_interfrence_size =  ------------------------------
-	 *                            (R0 - Ra) + ... + (R0 - Rp)
-	 *
-	 */
-
-	if (tc == tc_nums - 1) {
-		cbs[tc].max_interfrence_size = port_frame_max_size * 8;
-
-	} else if (tc == tc_nums - 2) {
-		if (!cbs[tc + 1].send_slope)
-			return -1;
-
-		cbs[tc].max_interfrence_size = (port_frame_max_size
-				+ cbs[tc + 1].tc_max_sized_frame
-				+ port_frame_max_size * (cbs[tc + 1].idle_slope
-				/ cbs[tc + 1].send_slope)) * 8;
-	} else {
-		max_interfrence_size = port_frame_max_size;
-		send_slope = 0;
-		for (i = tc + 1; i < tc_nums; i++) {
-			send_slope += cbs[i].send_slope;
-			max_interfrence_size += cbs[i].tc_max_sized_frame;
-		}
-		if (!send_slope)
-			return -1;
-
-		max_interfrence_size = ((u64)port_transmit_rate
-				* max_interfrence_size) / send_slope;
-		cbs[tc].max_interfrence_size = max_interfrence_size * 8;
-	}
-
-	if (!port_transmit_rate)
-		return -1;
-
-	cbs[tc].hi_credit = cbs[tc].max_interfrence_size * cbs[tc].bw / 100;
-	cbs[tc].lo_credit = cbs[tc].tc_max_sized_frame * (cbs[tc].send_slope
-			/ port_transmit_rate);
-	cbs[tc].tc = tc;
-
-	hi_credit = (ENETC_CLK * 100L) * (u64)cbs[tc].hi_credit
-			/ port_transmit_rate;
-	enetc_port_wr(&si->hw, ENETC_PTCCBSR1(tc), hi_credit);
-
-	/* Set bw register and enable this traffic class*/
-	enetc_port_wr(&si->hw, ENETC_PTCCBSR0(tc),
-		      (cbs[tc].bw & 0x7F) | (1 << 31));
-	cbs[tc].enable = true;
-
-	return 0;
-}
-
-static int enetc_get_cbs(struct net_device *ndev, u8 tc)
-{
-	struct enetc_ndev_priv *priv = netdev_priv(ndev);
-	struct enetc_si *si = priv->si;
-	struct enetc_cbs *ecbs = si->ecbs;
-	struct cbs *cbs;
-
-	if (!ecbs)
-		return -ENOMEM;
-	cbs = ecbs->cbs;
-	if (tc >= ecbs->tc_nums) {
-		dev_err(&ndev->dev, "The maximum of TC is %d\n", ecbs->tc_nums);
-		return -EINVAL;
-	}
-
-	return cbs[tc].bw;
-}
-
-static int enetc_set_tsd(struct net_device *ndev, struct tsn_tsd *ttsd)
-{
-	return 0;
-}
-
-static int enetc_get_tsd(struct net_device *ndev, struct tsn_tsd_status *tts)
-{
-	return 0;
-}
-
-static void enetc_cbs_init(struct enetc_si *si)
-{
-	struct enetc_ndev_priv *priv = netdev_priv(si->ndev);
-	u8 tc_nums;
-
-	tc_nums = priv->num_tx_rings;
-	si->ecbs = kzalloc(sizeof(*si->ecbs) +
-			   sizeof(struct cbs) * tc_nums, GFP_KERNEL);
-	if (!si->ecbs)
-		return;
-
-	si->ecbs->port_max_size_frame = si->ndev->mtu + ETH_HLEN
-						+ VLAN_HLEN + ETH_FCS_LEN;
-	si->ecbs->tc_nums = tc_nums;
-	si->ecbs->port_transmit_rate = priv->speed;
-
-	/*This trick is used only for CFP*/
-	if (!si->ecbs->port_transmit_rate)
-		si->ecbs->port_transmit_rate = 1000000000;
-
-	if (!si->ecbs->port_transmit_rate) {
-		dev_err(&si->pdev->dev, "Failure to get port speed for CBS\n");
-		kfree(si->ecbs);
-		si->ecbs = NULL;
-	}
-}
-
-static void enetc_qbv_init(struct enetc_hw *hw)
-{
-	/* Set PSPEED to be 1Gbps */
-	enetc_port_wr(hw, ENETC_PMR,
-		      (enetc_port_rd(hw, ENETC_PMR)
-		      & (~ENETC_PMR_PSPEED_MASK))
-		      | ENETC_PMR_PSPEED_1000M);
-}
-
-void enetc_tsn_init(struct net_device *ndev)
-{
-	struct enetc_ndev_priv *priv = netdev_priv(ndev);
-	struct enetc_si *si = priv->si;
-	u32 capability = 0;
-
-	capability = __enetc_tsn_get_cap(si);
-
-	if (capability & TSN_CAP_CBS)
-		enetc_cbs_init(si);
-
-	if (capability & TSN_CAP_QBV)
-		enetc_qbv_init(&si->hw);
-
-	if (capability & TSN_CAP_QCI)
-		enetc_qci_enable(&si->hw);
-
-	dev_info(&si->pdev->dev, "%s: setup done\n", __func__);
-}
-
-void enetc_tsn_deinit(struct net_device *ndev)
-{
-	struct enetc_ndev_priv *priv = netdev_priv(ndev);
-	struct enetc_si *si = priv->si;
-
-	dev_info(&si->pdev->dev, "%s: release\n", __func__);
-}
-
-static struct tsn_ops enetc_tsn_ops_full = {
-	.device_init = enetc_tsn_init,
-	.device_deinit = enetc_tsn_deinit,
-	.get_capability = enetc_tsn_get_capability,
-	.qbv_set = enetc_qbv_set,
-	.qbv_get = enetc_qbv_get,
-	.qbv_get_status = enetc_qbv_get_status,
-	.cb_streamid_set = enetc_cb_streamid_set,
-	.cb_streamid_get = enetc_cb_streamid_get,
-	.cb_streamid_counters_get = enetc_cb_streamid_counters_get,
-	.qci_get_maxcap = enetc_get_max_capa,
-	.qci_sfi_set = enetc_qci_sfi_set,
-	.qci_sfi_get = enetc_qci_sfi_get,
-	.qci_sfi_counters_get = enetc_qci_sfi_counters_get,
-	.qci_sgi_set = enetc_qci_sgi_set,
-	.qci_sgi_get = enetc_qci_sgi_get,
-	.qci_sgi_status_get = enetc_qci_sgi_status_get,
-	.qci_fmi_set = enetc_qci_fmi_set,
-	.qci_fmi_get = enetc_qci_fmi_get,
-	.qbu_set = enetc_qbu_set,
-	.qbu_get = enetc_qbu_get,
-	.cbs_set = enetc_set_cbs,
-	.cbs_get = enetc_get_cbs,
-	.tsd_set = enetc_set_tsd,
-	.tsd_get = enetc_get_tsd,
-};
-
-static struct tsn_ops enetc_tsn_ops_part = {
-	.device_init = enetc_tsn_init,
-	.device_deinit = enetc_tsn_deinit,
-	.get_capability = enetc_tsn_get_capability,
-	.cb_streamid_set = enetc_cb_streamid_set,
-	.cb_streamid_get = enetc_cb_streamid_get,
-	.cb_streamid_counters_get = enetc_cb_streamid_counters_get,
-	.qci_get_maxcap = enetc_get_max_capa,
-	.qci_sfi_set = enetc_qci_sfi_set,
-	.qci_sfi_get = enetc_qci_sfi_get,
-	.qci_sfi_counters_get = enetc_qci_sfi_counters_get,
-	.qci_sgi_set = enetc_qci_sgi_set,
-	.qci_sgi_get = enetc_qci_sgi_get,
-	.qci_sgi_status_get = enetc_qci_sgi_status_get,
-	.qci_fmi_set = enetc_qci_fmi_set,
-	.qci_fmi_get = enetc_qci_fmi_get,
-};
-
-void enetc_tsn_pf_init(struct net_device *netdev, struct pci_dev *pdev)
-{
-	int port = pdev->devfn & 0x7;
-
-	if (port == 1 || port == 3)
-		tsn_port_register(netdev, &enetc_tsn_ops_part,
-				  (u16)pdev->bus->number);
-	else
-		tsn_port_register(netdev, &enetc_tsn_ops_full,
-				  (u16)pdev->bus->number);
-}
-
-void enetc_tsn_pf_deinit(struct net_device *netdev)
-{
-	tsn_port_unregister(netdev);
-}
-#endif	/* #if IS_ENABLED(CONFIG_ENETC_TSN) */
-- 
2.25.1

